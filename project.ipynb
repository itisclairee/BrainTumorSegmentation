{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from kmeans import KMeans\n",
    "from matplotlib.colors import ListedColormap, BoundaryNorm\n",
    "import matplotlib.patches as mpatches\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact\n",
    "from scipy.ndimage import rotate\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D, concatenate, Dropout, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from keras.callbacks import CSVLogger\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping, TensorBoard\n",
    "import cv2\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory di Chiara\n",
    "#TRAIN_DATASET_PATH = \"/Users/chiaracangelosi/Documents/1-Uni/DataScience/Dataset/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/\"\n",
    "\n",
    "#Directory di Gianluca\n",
    "TRAIN_DATASET_PATH= \"C:/Users/g2not/Desktop/Università/Data Mining and Machine Learning/Progetto/brats20-dataset-training-validation/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/\"\n",
    "\n",
    "# Percorso completo del file FLAIR\n",
    "file_path = os.path.join(TRAIN_DATASET_PATH, \"BraTS20_Training_355\", \"BraTS20_Training_355_flair.nii\")\n",
    "\n",
    "# Carica il file .nii come array NumPy\n",
    "test_image_flair = nib.load(file_path).get_fdata()\n",
    "\n",
    "# Stampa informazioni sull'immagine\n",
    "print(\"Shape: \", test_image_flair.shape)\n",
    "print(\"Dtype: \", test_image_flair.dtype)\n",
    "print(\"Min: \", test_image_flair.min())\n",
    "print(\"Max: \", test_image_flair.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N.B. nel progetto github viene effettuato il rescaling slice-wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rescaling voxel-wise a [0, 1]\n",
    "test_image_flair = (test_image_flair - np.min(test_image_flair)) / (np.max(test_image_flair) - np.min(test_image_flair))\n",
    "\n",
    "# Verifica\n",
    "print(\"Rescaled min:\", test_image_flair.min())\n",
    "print(\"Rescaled max:\", test_image_flair.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carica il file .nii come array NumPy\n",
    "test_image_t1 = nib.load(TRAIN_DATASET_PATH + 'BraTS20_Training_355/BraTS20_Training_355_t1.nii').get_fdata()\n",
    "# Rescaling voxel-wise a [0, 1]\n",
    "test_image_t1 = (test_image_t1 - np.min(test_image_t1)) / (np.max(test_image_t1) - np.min(test_image_t1))\n",
    "\n",
    "# Carica il file .nii come array NumPy\n",
    "test_image_t1ce = nib.load(TRAIN_DATASET_PATH + 'BraTS20_Training_355/BraTS20_Training_355_t1ce.nii').get_fdata()\n",
    "# Rescaling voxel-wise a [0, 1]\n",
    "test_image_t1ce = (test_image_t1ce - np.min(test_image_t1ce)) / (np.max(test_image_t1ce) - np.min(test_image_t1ce))\n",
    "\n",
    "# Carica il file .nii come array NumPy\n",
    "test_image_t2 = nib.load(TRAIN_DATASET_PATH + 'BraTS20_Training_355/BraTS20_Training_355_t2.nii').get_fdata()\n",
    "# Rescaling voxel-wise a [0, 1]\n",
    "test_image_t2 = (test_image_t2 - np.min(test_image_t2)) / (np.max(test_image_t2) - np.min(test_image_t2))\n",
    "\n",
    "test_image_seg = nib.load(TRAIN_DATASET_PATH + 'BraTS20_Training_355/BraTS20_Training_355_seg.nii').get_fdata()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Colori per la maschera ===\n",
    "labels = [0, 1, 2, 4]\n",
    "colors = ['black', 'green', 'yellow', 'lightblue']\n",
    "class_names = ['Background (0)', 'NCR & NET (1)', 'Edema (2)', 'Enhancing Tumor (4)']\n",
    "cmap_mask = ListedColormap(colors)\n",
    "norm = BoundaryNorm([0, 0.5, 1.5, 3, 5], cmap_mask.N)\n",
    "\n",
    "# === Visualizzazione dinamica ===\n",
    "def show_slice(slice_idx):\n",
    "    fig, axs = plt.subplots(2, 3, figsize=(12, 8))\n",
    "\n",
    "    # MRI modalities\n",
    "    titles = ['T1', 'T1ce', 'T2', 'FLAIR']\n",
    "    volumes = [test_image_t1, test_image_t1ce, test_image_t2, test_image_flair]\n",
    "\n",
    "    for i in range(4):\n",
    "        axs[i // 3, i % 3].imshow(volumes[i][:, :, slice_idx], cmap='gray')\n",
    "        axs[i // 3, i % 3].set_title(titles[i])\n",
    "        axs[i // 3, i % 3].axis('off')\n",
    "\n",
    "    # Mask\n",
    "    axs[1, 1].imshow(test_image_seg[:, :, slice_idx], cmap=cmap_mask, norm=norm)\n",
    "    axs[1, 1].set_title('Mask')\n",
    "    axs[1, 1].axis('off')\n",
    "\n",
    "    # Legend\n",
    "    axs[1, 2].axis('off')\n",
    "    patches = [mpatches.Patch(color=colors[i], label=class_names[i]) for i in range(len(labels))]\n",
    "    axs[1, 2].legend(handles=patches, loc='center')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# === Interfaccia interattiva ===\n",
    "interact(\n",
    "    show_slice,\n",
    "    slice_idx=widgets.IntSlider(\n",
    "        value=95,\n",
    "        min=0,\n",
    "        max=test_image_t1.shape[2] - 1,\n",
    "        step=1,\n",
    "        description='Slice:',\n",
    "        continuous_update=True\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Funzione per visualizzare le tre viste ===\n",
    "def show_views(slice_idx):\n",
    "    fig = plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    # Transverse View (axial): [x, y, slice]\n",
    "    ax1 = fig.add_subplot(1, 3, 1)\n",
    "    ax1.imshow(test_image_t1ce[:, :, slice_idx], cmap='gray')\n",
    "    ax1.set_title(f'T1 - Transverse View (Z={slice_idx})')\n",
    "    ax1.axis('off')\n",
    "    \n",
    "    # Frontal View (coronal): [x, slice, z] → rotate for readability\n",
    "    ax2 = fig.add_subplot(1, 3, 2)\n",
    "    ax2.imshow(rotate(test_image_t1ce[:, slice_idx, :], 90, reshape=True), cmap='gray')\n",
    "    ax2.set_title(f'T1 - Frontal View (Y={slice_idx})')\n",
    "    ax2.axis('off')\n",
    "    \n",
    "    # Sagittal View: [slice, y, z] → rotate for readability\n",
    "    ax3 = fig.add_subplot(1, 3, 3)\n",
    "    ax3.imshow(rotate(test_image_t1ce[slice_idx, :, :], 90, reshape=True), cmap='gray')\n",
    "    ax3.set_title(f'T1 - Sagittal View (X={slice_idx})')\n",
    "    ax3.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# === Slider interattivo ===\n",
    "# Usa la dimensione più piccola per non eccedere l'indice valido in nessuna direzione\n",
    "max_index = min(test_image_t1ce.shape)\n",
    "\n",
    "interact(\n",
    "    show_views,\n",
    "    slice_idx=widgets.IntSlider(\n",
    "        value=95,\n",
    "        min=0,\n",
    "        max=max_index - 1,\n",
    "        step=1,\n",
    "        description='Slice:',\n",
    "        continuous_update=True\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Mappa colori e normalizzazione (adatta a BraTS ad esempio)\n",
    "labels = [0, 1, 2, 4]\n",
    "colors = ['black', 'green', 'yellow', 'lightblue']\n",
    "class_names = ['Background (0)', 'NCR/NET (1)', 'Edema (2)', 'Enhancing Tumor (4)']\n",
    "cmap = ListedColormap(colors)\n",
    "norm = BoundaryNorm([0, 0.5, 1.5, 3, 5], len(colors))\n",
    "\n",
    "# === Funzione dinamica\n",
    "def show_segmented_slice(slice_idx):\n",
    "    # Isola ogni classe come maschera separata (usando NaN per trasparenza)\n",
    "    seg_0 = test_image_seg.copy()\n",
    "    seg_0[seg_0 != 0] = np.nan\n",
    "    \n",
    "    seg_1 = test_image_seg.copy()\n",
    "    seg_1[seg_1 != 1] = np.nan\n",
    "    \n",
    "    seg_2 = test_image_seg.copy()\n",
    "    seg_2[seg_2 != 2] = np.nan\n",
    "    \n",
    "    seg_4 = test_image_seg.copy()\n",
    "    seg_4[seg_4 != 4] = np.nan\n",
    "\n",
    "    # Legenda personalizzata\n",
    "    legend = [plt.Rectangle((0, 0), 1, 1, color=cmap(i), label=class_names[i]) for i in range(len(class_names))]\n",
    "\n",
    "    # Plot\n",
    "    fig, ax = plt.subplots(1, 5, figsize=(20, 5))\n",
    "\n",
    "    ax[0].imshow(test_image_seg[:, :, slice_idx], cmap=cmap, norm=norm)\n",
    "    ax[0].set_title('Original Segmentation')\n",
    "    ax[0].legend(handles=legend, loc='lower left')\n",
    "    ax[0].axis('off')\n",
    "\n",
    "    ax[1].imshow(seg_0[:, :, slice_idx], cmap=cmap, norm=norm)\n",
    "    ax[1].set_title('Class 0 (Background)')\n",
    "    ax[1].axis('off')\n",
    "\n",
    "    ax[2].imshow(seg_1[:, :, slice_idx], cmap=cmap, norm=norm)\n",
    "    ax[2].set_title('Class 1 (NCR/NET)')\n",
    "    ax[2].axis('off')\n",
    "\n",
    "    ax[3].imshow(seg_2[:, :, slice_idx], cmap=cmap, norm=norm)\n",
    "    ax[3].set_title('Class 2 (Edema)')\n",
    "    ax[3].axis('off')\n",
    "\n",
    "    ax[4].imshow(seg_4[:, :, slice_idx], cmap=cmap, norm=norm)\n",
    "    ax[4].set_title('Class 4 (Enhancing Tumor)')\n",
    "    ax[4].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# === Slider interattivo\n",
    "interact(\n",
    "    show_segmented_slice,\n",
    "    slice_idx=widgets.IntSlider(\n",
    "        value=95,\n",
    "        min=0,\n",
    "        max=test_image_seg.shape[2] - 1,\n",
    "        step=1,\n",
    "        description='Slice:',\n",
    "        continuous_update=True\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === Parametri ===\n",
    "slice_idx = 95\n",
    "k = 3  # Numero di cluster per K-Means\n",
    " \n",
    "# === Estrai le slice da ciascuna modalità ===\n",
    "flair_slice = test_image_flair[:, :, slice_idx]\n",
    "t1_slice = test_image_t1[:, :, slice_idx]\n",
    "t1ce_slice = test_image_t1ce[:, :, slice_idx]\n",
    "t2_slice = test_image_t2[:, :, slice_idx]\n",
    "mask_slice = test_image_seg[:, :, slice_idx]\n",
    " \n",
    "# === Crea matrice (H, W, 3) e reshape in (N_pixel, 3) ===\n",
    "X = np.stack([flair_slice, t1_slice, t1ce_slice, t2_slice], axis=-1)\n",
    "X_reshaped = X.reshape((-1, 4)).astype(np.float32)\n",
    " \n",
    "# === Applica K-Means ===\n",
    "km = KMeans(n_clus=k)\n",
    "km.fit(X_reshaped)\n",
    "clusters = km.getClusters()\n",
    " \n",
    "# === Reshape per visualizzazione ===\n",
    "segmented_image = clusters.reshape(flair_slice.shape)\n",
    " \n",
    "# === Mappa colori per K-Means (colori arbitrari) ===\n",
    "cmap_kmeans = ListedColormap(['orange', 'purple', 'green', 'blue', 'pink'])\n",
    " \n",
    "# === Mappa colori per maschera reale ===\n",
    "labels = [0, 1, 2, 4]\n",
    "colors = ['black', 'green', 'yellow', 'lightblue']\n",
    "class_names = ['Background (0)', 'NCR & NET (1)', 'Edema (2)', 'Enhancing Tumor (4)']\n",
    "cmap_mask = ListedColormap(colors)\n",
    "norm = BoundaryNorm([0, 0.5, 1.5, 3, 5], cmap_mask.N)\n",
    " \n",
    "# === Visualizzazione ===\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12, 6))\n",
    " \n",
    "axs[0].imshow(segmented_image, cmap=cmap_kmeans)\n",
    "axs[0].set_title(f'K-Means (k={k}) - Slice {slice_idx}')\n",
    "axs[0].axis('off')\n",
    " \n",
    "axs[1].imshow(mask_slice, cmap=cmap_mask, norm=norm)\n",
    "axs[1].set_title('Ground Truth (BraTS Segmentation)')\n",
    "axs[1].axis('off')\n",
    " \n",
    "# Legenda della maschera reale\n",
    "patches = [mpatches.Patch(color=colors[i], label=class_names[i]) for i in range(len(labels))]\n",
    "axs[1].legend(handles=patches, loc='lower left', bbox_to_anchor=(1.05, 0))\n",
    " \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ottieni la lista degli ID (ultime parti dei path delle directory)\n",
    "train_and_test_ids = [f.name for f in os.scandir(TRAIN_DATASET_PATH) if f.is_dir()]\n",
    "\n",
    "# Split in: 80% train+test, 20% validation\n",
    "train_test_ids, val_ids = train_test_split(train_and_test_ids, test_size=0.2, random_state=42)\n",
    "\n",
    "# Split train+test in: 85% train, 15% test (≈12% del totale va a test)\n",
    "train_ids, test_ids = train_test_split(train_test_ids, test_size=0.15, random_state=42)\n",
    "\n",
    "print(f\"Train length: {len(train_ids)}\")\n",
    "print(f\"Validation length: {len(val_ids)}\")\n",
    "print(f\"Test length: {len(test_ids)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.pie(\n",
    "        [len(train_ids), len(val_ids), len(test_ids)],\n",
    "        labels=['Train', 'Validation', 'Test'],\n",
    "       )\n",
    "\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "plt.ylabel('Number of Images')\n",
    "plt.title('Data Distribution')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEGMENT_CLASSES = {\n",
    "    0 : 'NOT tumor',\n",
    "    1 : 'NECROTIC/CORE', \n",
    "    2 : 'EDEMA',\n",
    "    3 : 'ENHANCING'\n",
    "}\n",
    "\n",
    "# Select Slices and Image Size\n",
    "VOLUME_SLICES = 100\n",
    "VOLUME_START_AT = 22 \n",
    "IMG_SIZE=128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, list_IDs, dim=(IMG_SIZE,IMG_SIZE), batch_size = 1, n_channels = 2, shuffle=True):\n",
    "        'Initialization'\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.list_IDs = list_IDs\n",
    "        self.n_channels = n_channels\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        Batch_ids = [self.list_IDs[k] for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(Batch_ids)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, Batch_ids):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        # Initialization\n",
    "        X = np.zeros((self.batch_size*VOLUME_SLICES, *self.dim, self.n_channels))\n",
    "        y = np.zeros((self.batch_size*VOLUME_SLICES, 240, 240))\n",
    "        Y = np.zeros((self.batch_size*VOLUME_SLICES, *self.dim, 4))\n",
    "\n",
    "\n",
    "        # Generate data\n",
    "        for c, i in enumerate(Batch_ids):\n",
    "            case_path = os.path.join(TRAIN_DATASET_PATH, i)\n",
    "\n",
    "            data_path = os.path.join(case_path, f'{i}_flair.nii');\n",
    "            flair = nib.load(data_path).get_fdata()\n",
    "\n",
    "            data_path = os.path.join(case_path, f'{i}_t1ce.nii');\n",
    "            t1ce = nib.load(data_path).get_fdata()\n",
    "\n",
    "            data_path = os.path.join(case_path, f'{i}_seg.nii');\n",
    "            seg = nib.load(data_path).get_fdata()\n",
    "\n",
    "            for j in range(VOLUME_SLICES):\n",
    "                 X[j +VOLUME_SLICES*c,:,:,0] = cv2.resize(flair[:,:,j+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE));\n",
    "                 X[j +VOLUME_SLICES*c,:,:,1] = cv2.resize(t1ce[:,:,j+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE));\n",
    "\n",
    "                 y[j +VOLUME_SLICES*c] = seg[:,:,j+VOLUME_START_AT];\n",
    "\n",
    "        # Generate masks\n",
    "        y[y==4] = 3;\n",
    "        mask = tf.one_hot(y, 4);\n",
    "        Y = tf.image.resize(mask, (IMG_SIZE, IMG_SIZE));\n",
    "        return X/np.max(X), Y\n",
    "\n",
    "training_generator = DataGenerator(train_ids)\n",
    "valid_generator = DataGenerator(val_ids)\n",
    "test_generator = DataGenerator(test_ids)\n",
    "\n",
    "\n",
    "print(\"Numero di batch nel training set:\", len(training_generator))\n",
    "print(\"Numero di batch nel validation set:\", len(valid_generator))\n",
    "print(\"Numero di batch nel test set:\", len(test_generator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to display one slice and its segmentation\n",
    "def display_slice_and_segmentation(flair, t1ce, segmentation):\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(10, 5))\n",
    "\n",
    "    axes[0].imshow(flair, cmap='gray')\n",
    "    axes[0].set_title('Flair')\n",
    "    axes[0].axis('off')\n",
    "\n",
    "    axes[1].imshow(t1ce, cmap='gray')\n",
    "    axes[1].set_title('T1CE')\n",
    "    axes[1].axis('off')\n",
    "\n",
    "    axes[2].imshow(segmentation) # Displaying segmentation\n",
    "    axes[2].set_title('Segmentation')\n",
    "    axes[2].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Retrieve the ninth batch from the training generator\n",
    "X_batch, Y_batch = training_generator[8]\n",
    "\n",
    "# Extract Flair, T1CE, and segmentation from the batch\n",
    "flair_batch = X_batch[:, :, :, 0]\n",
    "t1ce_batch = X_batch[:, :, :, 1]\n",
    "segmentation_batch = np.argmax(Y_batch, axis=-1)  # Convert one-hot encoded to categorical\n",
    "\n",
    "# Extract the 50th slice from Flair, T1CE, and segmentation\n",
    "slice_index = 60  # Indexing starts from 0\n",
    "slice_flair = flair_batch[slice_index]\n",
    "slice_t1ce = t1ce_batch[slice_index]\n",
    "slice_segmentation = segmentation_batch[slice_index]\n",
    "\n",
    "# Display the 50th slice and its segmentation\n",
    "display_slice_and_segmentation(slice_flair, slice_t1ce, slice_segmentation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pixel_accuracy function calculates the percentage of correctly classified pixels in an image segmentation task. It compares the predicted class and the true class for each pixel and returns the overall mean accuracy.\n",
    "However, this metric can be misleading in imbalanced datasets, where the background class is overrepresented since the model may achieve high accuracy by mostly predicting the background, while failing to correctly identify smaller but important regions like tumors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The pixel_accuracy function calculates the percentage of correctly classified pixels, \n",
    "#that is how many pixels the model predicted with the correct class out of the total number of pixels.\n",
    "def pixel_accuracy(y_true, y_pred):\n",
    "    y_true_labels = K.argmax(y_true, axis=-1)\n",
    "    y_pred_labels = K.argmax(y_pred, axis=-1)\n",
    "    matches = K.cast(K.equal(y_true_labels, y_pred_labels), dtype='float32')\n",
    "    return K.mean(matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean_iou function calculates the Intersection over Union (IoU) for each of the 4 segmentation classes: no tumor, necrotic core, edema, and enhancing tumor. For each class, it computes the area of overlap between the predicted and ground truth masks divided by the area of their union, then returns the average IoU across all classes.\n",
    "\n",
    "This metric is particularly useful in medical image segmentation tasks, as it accounts for both false positives and false negatives.\n",
    "\n",
    "IoU = (Area of Overlap) / (Area of Union) = |A ∩ B| / |A ∪ B|\n",
    "\n",
    "Where:\n",
    "A is the predicted mask and B is the ground truth mask\n",
    "\n",
    "\n",
    "The IoU loss is defined as:\n",
    "\n",
    "IoU Loss = 1 − IoU\n",
    "\n",
    "This motivates the network to enlarge the IoU in order to minimize the IoU loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The mean_iou function calculates the Intersection over Union (IoU) for each of the 4 classes (no tumor, necrotic, edema, enhancing), \n",
    "#and then returns the average IoU across all classes.\n",
    "def mean_iou(y_true, y_pred, epsilon=1e-6):\n",
    "    iou_scores = []\n",
    "    for i in range(4):\n",
    "        y_true_c = tf.reshape(y_true[:, :, :, i], [-1])\n",
    "        y_pred_c = tf.reshape(y_pred[:, :, :, i], [-1])\n",
    "        intersection = K.sum(y_true_c * y_pred_c)\n",
    "        union = K.sum(y_true_c) + K.sum(y_pred_c) - intersection\n",
    "        iou = (intersection + epsilon) / (union + epsilon)\n",
    "        iou_scores.append(iou)\n",
    "    return K.mean(tf.stack(iou_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dice_coef function computes the average Dice coefficient across 4 segmentation classes. It measures the overlap between predicted and ground truth masks:\n",
    "\n",
    "Dice = (2 x Area of overlapped) / (total Area)\n",
    " \n",
    "Dice Loss = 1 − Dice Coefficient\n",
    "\n",
    "This metric is very effective in medical image segmentation, where foreground regions (e.g., tumors) are small and imbalanced. Dice Loss gives more weight to overlapping areas, producing stronger gradients and encouraging the network to segment structures precisely, rather than defaulting to background predictions as can happen with IoU loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function dice_coef calculates the average Dice coefficient across all 4 segmentation classes.\n",
    "def dice_coef(y_true, y_pred, smooth=1.0):\n",
    "    total_dice = 0\n",
    "    for i in range(4):\n",
    "        y_true_f = tf.reshape(y_true[:, :, :, i], [-1])\n",
    "        y_pred_f = tf.reshape(y_pred[:, :, :, i], [-1])\n",
    "        intersection = K.sum(y_true_f * y_pred_f)\n",
    "        dice = (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "        total_dice += dice\n",
    "    return total_dice / 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each class (necrotic, edema, enhancing) represents a distinct tissue type with different clinical relevance.\n",
    "By computing the Dice score separately, we can better understand how well the model segments each region, rather than relying only on an average result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define per class evaluation of dice coef\n",
    "def dice_coef_necrotic(y_true, y_pred, epsilon=1e-6):\n",
    "    intersection = K.sum(K.abs(y_true[:,:,:,1] * y_pred[:,:,:,1]))\n",
    "    return (2. * intersection) / (K.sum(K.square(y_true[:,:,:,1])) + K.sum(K.square(y_pred[:,:,:,1])) + epsilon)\n",
    "\n",
    "def dice_coef_edema(y_true, y_pred, epsilon=1e-6):\n",
    "    intersection = K.sum(K.abs(y_true[:,:,:,2] * y_pred[:,:,:,2]))\n",
    "    return (2. * intersection) / (K.sum(K.square(y_true[:,:,:,2])) + K.sum(K.square(y_pred[:,:,:,2])) + epsilon)\n",
    "\n",
    "def dice_coef_enhancing(y_true, y_pred, epsilon=1e-6):\n",
    "    intersection = K.sum(K.abs(y_true[:,:,:,3] * y_pred[:,:,:,3]))\n",
    "    return (2. * intersection) / (K.sum(K.square(y_true[:,:,:,3])) + K.sum(K.square(y_pred[:,:,:,3])) + epsilon) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sensitivity function (also known as recall or true positive rate) computes how well the model detects positive pixels for each tumor class (necrotic, edema, enhancing). It ignores class 0 (background) and returns the average sensitivity across the 3 tumor regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sensitivity(y_true, y_pred, epsilon=1e-6):\n",
    "    sensitivities = []\n",
    "    for i in range(1, 4):  # class 0 is ignored\n",
    "        y_true_c = tf.reshape(y_true[:, :, :, i], [-1])\n",
    "        y_pred_c = tf.reshape(y_pred[:, :, :, i], [-1])\n",
    "        tp = K.sum(K.round(K.clip(y_true_c * y_pred_c, 0, 1)))\n",
    "        fn = K.sum(K.round(K.clip(y_true_c * (1 - y_pred_c), 0, 1)))\n",
    "        recall = tp / (tp + fn + epsilon)\n",
    "        sensitivities.append(recall)\n",
    "    return K.mean(tf.stack(sensitivities))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The precision function computes the positive predictive value for each tumor class,  measuring the proportion of predicted positive pixels that are actually positive and ignoring the background class (0). It returns the average precision across the 3 tumor regions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(y_true, y_pred, epsilon=1e-6):\n",
    "    precisions = []\n",
    "    for i in range(1, 4):  # class 0 is ignored\n",
    "        y_true_c = tf.reshape(y_true[:, :, :, i], [-1])\n",
    "        y_pred_c = tf.reshape(y_pred[:, :, :, i], [-1])\n",
    "        tp = K.sum(K.round(K.clip(y_true_c * y_pred_c, 0, 1)))\n",
    "        fp = K.sum(K.round(K.clip((1 - y_true_c) * y_pred_c, 0, 1)))\n",
    "        prec = tp / (tp + fp + epsilon)\n",
    "        precisions.append(prec)\n",
    "    return K.mean(tf.stack(precisions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The specificity function calculates the true negative rate for each tumor class, measuring the proportion of negative ground truth pixels correctly predicted as negative and ignoring the background class (0). It returns the average specificity across the 3 tumor regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "def specificity(y_true, y_pred, epsilon=1e-6):\n",
    "    specificities = []\n",
    "    for i in range(1, 4):  # class 0 is ignored\n",
    "        y_true_c = tf.reshape(y_true[:, :, :, i], [-1])\n",
    "        y_pred_c = tf.reshape(y_pred[:, :, :, i], [-1])\n",
    "        \n",
    "        tn = K.sum(K.round(K.clip((1 - y_true_c) * (1 - y_pred_c), 0, 1)))\n",
    "        fp = K.sum(K.round(K.clip((1 - y_true_c) * y_pred_c, 0, 1)))\n",
    "        \n",
    "        spec = tn / (tn + fp + epsilon)\n",
    "        specificities.append(spec)\n",
    "    \n",
    "    return K.mean(tf.stack(specificities))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_unet(inputs, ker_init, dropout):\n",
    "    conv1 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(inputs)\n",
    "    conv1 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv1)\n",
    "\n",
    "    pool = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    conv = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(pool)\n",
    "    conv = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv)\n",
    "\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv)\n",
    "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(pool1)\n",
    "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv2)\n",
    "\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(pool2)\n",
    "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv3)\n",
    "\n",
    "\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    conv5 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(pool4)\n",
    "    conv5 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv5)\n",
    "    drop5 = Dropout(dropout)(conv5)\n",
    "\n",
    "    up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(UpSampling2D(size = (2,2))(drop5))\n",
    "    merge7 = concatenate([conv3,up7], axis = 3)\n",
    "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(merge7)\n",
    "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv7)\n",
    "\n",
    "    up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(UpSampling2D(size = (2,2))(conv7))\n",
    "    merge8 = concatenate([conv2,up8], axis = 3)\n",
    "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(merge8)\n",
    "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv8)\n",
    "\n",
    "    up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(UpSampling2D(size = (2,2))(conv8))\n",
    "    merge9 = concatenate([conv,up9], axis = 3)\n",
    "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(merge9)\n",
    "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv9)\n",
    "\n",
    "    up = Conv2D(32, 2, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(UpSampling2D(size = (2,2))(conv9))\n",
    "    merge = concatenate([conv1,up], axis = 3)\n",
    "    conv = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(merge)\n",
    "    conv = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv)\n",
    "\n",
    "    conv10 = Conv2D(4, (1,1), activation = 'softmax')(conv)\n",
    "\n",
    "    return Model(inputs = inputs, outputs = conv10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = Input((IMG_SIZE, IMG_SIZE, 2))\n",
    "\n",
    "model = build_unet(input_layer, 'he_normal', 0.2)\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "              metrics = ['accuracy',tf.keras.metrics.MeanIoU(num_classes=4), dice_coef, precision, sensitivity, specificity, dice_coef_necrotic, dice_coef_edema ,dice_coef_enhancing])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "      keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "                            patience=2, min_lr=0.000001, verbose=1),\n",
    "      keras.callbacks.ModelCheckpoint(filepath = 'model_{epoch:02d}-{val_loss:.6f}.weights.h5', \n",
    "                          verbose=1, save_best_only=True, save_weights_only = True),\n",
    "      CSVLogger('training.log', separator=',', append=False)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code for training the model:\n",
    "\n",
    "\n",
    "K.clear_session()\n",
    "\n",
    "history =  model.fit(training_generator,\n",
    "                    epochs=35,\n",
    "                    steps_per_epoch=len(train_ids),\n",
    "                    callbacks= callbacks,\n",
    "                    validation_data = valid_generator\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#history = pd.read_csv('/Users/chiaracangelosi/Documents/1-Uni/DataScience/Dataset/data/Progetto Data/training.log', sep=',', engine='python')\n",
    "history = pd.read_csv('C:/Users/g2not/Desktop/Università/Data Mining and Machine Learning/Progetto/training.log', sep=',', engine='python')\n",
    "\n",
    "hist = history\n",
    "\n",
    "acc = hist['accuracy']\n",
    "val_acc = hist['val_accuracy']\n",
    "\n",
    "epoch = range(len(acc))\n",
    "\n",
    "loss = hist['loss']\n",
    "val_loss = hist['val_loss']\n",
    "\n",
    "train_dice = hist['dice_coef']\n",
    "val_dice = hist['val_dice_coef']\n",
    "\n",
    "f, ax = plt.subplots(1, 4, figsize=(16, 8))\n",
    "\n",
    "ax[0].plot(epoch, acc, 'b', label='Training Accuracy')\n",
    "ax[0].plot(epoch, val_acc, 'r', label='Validation Accuracy')\n",
    "ax[0].legend()\n",
    "ax[0].set_title('Accuracy')\n",
    "\n",
    "ax[1].plot(epoch, loss, 'b', label='Training Loss')\n",
    "ax[1].plot(epoch, val_loss, 'r', label='Validation Loss')\n",
    "ax[1].legend()\n",
    "ax[1].set_title('Loss')\n",
    "\n",
    "ax[2].plot(epoch, train_dice, 'b', label='Training Dice Coef')\n",
    "ax[2].plot(epoch, val_dice, 'r', label='Validation Dice Coef')\n",
    "ax[2].legend()\n",
    "ax[2].set_title('Dice Coefficient')\n",
    "\n",
    "ax[3].plot(epoch, hist['mean_io_u'], 'b', label='Training Mean IOU')\n",
    "ax[3].plot(epoch, hist['val_mean_io_u'], 'r', label='Validation Mean IOU')\n",
    "ax[3].legend()\n",
    "ax[3].set_title('Mean IOU')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TO DO LIST:\n",
    "Hausdorff distance \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
