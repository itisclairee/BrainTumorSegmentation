{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from kmeans import KMeans\n",
    "from matplotlib.colors import ListedColormap, BoundaryNorm\n",
    "import matplotlib.patches as mpatches\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact\n",
    "from scipy.ndimage import rotate\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D, concatenate, Dropout, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from keras.callbacks import CSVLogger\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping, TensorBoard\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from IPython.display import display\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory di Chiara\n",
    "TRAIN_DATASET_PATH = \"/Users/chiaracangelosi/Documents/1-Uni/DataScience/Dataset/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/\"\n",
    "\n",
    "#Directory di Gianluca\n",
    "#TRAIN_DATASET_PATH= \"C:/Users/g2not/Desktop/Università/Data Mining and Machine Learning/Progetto/brats20-dataset-training-validation/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/\"\n",
    "\n",
    "# Carica il file .nii come array NumPy\n",
    "test_image_flair = nib.load(TRAIN_DATASET_PATH + \"BraTS20_Training_355/BraTS20_Training_355_flair.nii\").get_fdata()\n",
    "\n",
    "# Stampa informazioni sull'immagine\n",
    "print(\"Shape: \", test_image_flair.shape)\n",
    "print(\"Dtype: \", test_image_flair.dtype)\n",
    "print(\"Min: \", test_image_flair.min())\n",
    "print(\"Max: \", test_image_flair.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rescaling voxel-wise a [0, 1]\n",
    "test_image_flair = (test_image_flair - np.min(test_image_flair)) / (np.max(test_image_flair) - np.min(test_image_flair))\n",
    "\n",
    "# Verifica\n",
    "print(\"Rescaled min:\", test_image_flair.min())\n",
    "print(\"Rescaled max:\", test_image_flair.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carica il file .nii come array NumPy\n",
    "test_image_t1 = nib.load(TRAIN_DATASET_PATH + 'BraTS20_Training_355/BraTS20_Training_355_t1.nii').get_fdata()\n",
    "# Rescaling voxel-wise a [0, 1]\n",
    "test_image_t1 = (test_image_t1 - np.min(test_image_t1)) / (np.max(test_image_t1) - np.min(test_image_t1))\n",
    "\n",
    "# Carica il file .nii come array NumPy\n",
    "test_image_t1ce = nib.load(TRAIN_DATASET_PATH + 'BraTS20_Training_355/BraTS20_Training_355_t1ce.nii').get_fdata()\n",
    "# Rescaling voxel-wise a [0, 1]\n",
    "test_image_t1ce = (test_image_t1ce - np.min(test_image_t1ce)) / (np.max(test_image_t1ce) - np.min(test_image_t1ce))\n",
    "\n",
    "# Carica il file .nii come array NumPy\n",
    "test_image_t2 = nib.load(TRAIN_DATASET_PATH + 'BraTS20_Training_355/BraTS20_Training_355_t2.nii').get_fdata()\n",
    "# Rescaling voxel-wise a [0, 1]\n",
    "test_image_t2 = (test_image_t2 - np.min(test_image_t2)) / (np.max(test_image_t2) - np.min(test_image_t2))\n",
    "\n",
    "test_image_seg = nib.load(TRAIN_DATASET_PATH + 'BraTS20_Training_355/BraTS20_Training_355_seg.nii').get_fdata()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Colori per la maschera ===\n",
    "labels = [0, 1, 2, 4]\n",
    "colors = ['black', 'green', 'yellow', 'lightblue']\n",
    "class_names = ['Background (0)', 'NCR & NET (1)', 'Edema (2)', 'Enhancing Tumor (4)']\n",
    "cmap_mask = ListedColormap(colors)\n",
    "norm = BoundaryNorm([0, 0.5, 1.5, 3, 5], cmap_mask.N)\n",
    "\n",
    "# === Visualizzazione dinamica ===\n",
    "def show_slice(slice_idx):\n",
    "    fig, axs = plt.subplots(2, 3, figsize=(12, 8))\n",
    "\n",
    "    # MRI modalities\n",
    "    titles = ['T1', 'T1ce', 'T2', 'FLAIR']\n",
    "    volumes = [test_image_t1, test_image_t1ce, test_image_t2, test_image_flair]\n",
    "\n",
    "    for i in range(4):\n",
    "        axs[i // 3, i % 3].imshow(volumes[i][:, :, slice_idx], cmap='gray')\n",
    "        axs[i // 3, i % 3].set_title(titles[i])\n",
    "        axs[i // 3, i % 3].axis('off')\n",
    "\n",
    "    # Mask\n",
    "    axs[1, 1].imshow(test_image_seg[:, :, slice_idx], cmap=cmap_mask, norm=norm)\n",
    "    axs[1, 1].set_title('Mask')\n",
    "    axs[1, 1].axis('off')\n",
    "\n",
    "    # Legend\n",
    "    axs[1, 2].axis('off')\n",
    "    patches = [mpatches.Patch(color=colors[i], label=class_names[i]) for i in range(len(labels))]\n",
    "    axs[1, 2].legend(handles=patches, loc='center')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# === Interfaccia interattiva ===\n",
    "interact(\n",
    "    show_slice,\n",
    "    slice_idx=widgets.IntSlider(\n",
    "        value=95,\n",
    "        min=0,\n",
    "        max=test_image_t1.shape[2] - 1,\n",
    "        step=1,\n",
    "        description='Slice:',\n",
    "        continuous_update=True\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Funzione per visualizzare le tre viste ===\n",
    "def show_views(slice_idx):\n",
    "    fig = plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    # Transverse View (axial): [x, y, slice]\n",
    "    ax1 = fig.add_subplot(1, 3, 1)\n",
    "    ax1.imshow(test_image_t1ce[:, :, slice_idx], cmap='gray')\n",
    "    ax1.set_title(f'T1 - Transverse View (Z={slice_idx})')\n",
    "    ax1.axis('off')\n",
    "    \n",
    "    # Frontal View (coronal): [x, slice, z] → rotate for readability\n",
    "    ax2 = fig.add_subplot(1, 3, 2)\n",
    "    ax2.imshow(rotate(test_image_t1ce[:, slice_idx, :], 90, reshape=True), cmap='gray')\n",
    "    ax2.set_title(f'T1 - Frontal View (Y={slice_idx})')\n",
    "    ax2.axis('off')\n",
    "    \n",
    "    # Sagittal View: [slice, y, z] → rotate for readability\n",
    "    ax3 = fig.add_subplot(1, 3, 3)\n",
    "    ax3.imshow(rotate(test_image_t1ce[slice_idx, :, :], 90, reshape=True), cmap='gray')\n",
    "    ax3.set_title(f'T1 - Sagittal View (X={slice_idx})')\n",
    "    ax3.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# === Slider interattivo ===\n",
    "# Usa la dimensione più piccola per non eccedere l'indice valido in nessuna direzione\n",
    "max_index = min(test_image_t1ce.shape)\n",
    "\n",
    "interact(\n",
    "    show_views,\n",
    "    slice_idx=widgets.IntSlider(\n",
    "        value=95,\n",
    "        min=0,\n",
    "        max=max_index - 1,\n",
    "        step=1,\n",
    "        description='Slice:',\n",
    "        continuous_update=True\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Mappa colori e normalizzazione (adatta a BraTS ad esempio)\n",
    "labels = [0, 1, 2, 4]\n",
    "colors = ['black', 'green', 'yellow', 'lightblue']\n",
    "class_names = ['Background (0)', 'NCR/NET (1)', 'Edema (2)', 'Enhancing Tumor (4)']\n",
    "cmap = ListedColormap(colors)\n",
    "norm = BoundaryNorm([0, 0.5, 1.5, 3, 5], len(colors))\n",
    "\n",
    "# === Funzione dinamica\n",
    "def show_segmented_slice(slice_idx):\n",
    "    # Isola ogni classe come maschera separata (usando NaN per trasparenza)\n",
    "    seg_0 = test_image_seg.copy()\n",
    "    seg_0[seg_0 != 0] = np.nan\n",
    "    \n",
    "    seg_1 = test_image_seg.copy()\n",
    "    seg_1[seg_1 != 1] = np.nan\n",
    "    \n",
    "    seg_2 = test_image_seg.copy()\n",
    "    seg_2[seg_2 != 2] = np.nan\n",
    "    \n",
    "    seg_4 = test_image_seg.copy()\n",
    "    seg_4[seg_4 != 4] = np.nan\n",
    "\n",
    "    # Legenda personalizzata\n",
    "    legend = [plt.Rectangle((0, 0), 1, 1, color=cmap(i), label=class_names[i]) for i in range(len(class_names))]\n",
    "\n",
    "    # Plot\n",
    "    fig, ax = plt.subplots(1, 5, figsize=(20, 5))\n",
    "\n",
    "    ax[0].imshow(test_image_seg[:, :, slice_idx], cmap=cmap, norm=norm)\n",
    "    ax[0].set_title('Original Segmentation')\n",
    "    ax[0].legend(handles=legend, loc='lower left')\n",
    "    ax[0].axis('off')\n",
    "\n",
    "    ax[1].imshow(seg_0[:, :, slice_idx], cmap=cmap, norm=norm)\n",
    "    ax[1].set_title('Class 0 (Background)')\n",
    "    ax[1].axis('off')\n",
    "\n",
    "    ax[2].imshow(seg_1[:, :, slice_idx], cmap=cmap, norm=norm)\n",
    "    ax[2].set_title('Class 1 (NCR/NET)')\n",
    "    ax[2].axis('off')\n",
    "\n",
    "    ax[3].imshow(seg_2[:, :, slice_idx], cmap=cmap, norm=norm)\n",
    "    ax[3].set_title('Class 2 (Edema)')\n",
    "    ax[3].axis('off')\n",
    "\n",
    "    ax[4].imshow(seg_4[:, :, slice_idx], cmap=cmap, norm=norm)\n",
    "    ax[4].set_title('Class 4 (Enhancing Tumor)')\n",
    "    ax[4].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# === Slider interattivo\n",
    "interact(\n",
    "    show_segmented_slice,\n",
    "    slice_idx=widgets.IntSlider(\n",
    "        value=95,\n",
    "        min=0,\n",
    "        max=test_image_seg.shape[2] - 1,\n",
    "        step=1,\n",
    "        description='Slice:',\n",
    "        continuous_update=True\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Parametri\n",
    "slice_idx = 95\n",
    "k = 5  # Numero di cluster per K-Means\n",
    " \n",
    "#Slice delle differenti modalità\n",
    "flair_slice = test_image_flair[:, :, slice_idx]\n",
    "t1_slice = test_image_t1[:, :, slice_idx]\n",
    "t1ce_slice = test_image_t1ce[:, :, slice_idx]\n",
    "t2_slice = test_image_t2[:, :, slice_idx]\n",
    "mask_slice = test_image_seg[:, :, slice_idx]\n",
    " \n",
    "# Le slice vengono congiunte attraverso il metodo stack, che unisce più array lungo una\n",
    "# nuova dimensione. Con un reshape, ogni pixel viene rappresentato da un vettore di 4 valori (uno per ogni modalità)\n",
    "\n",
    "X = np.stack([flair_slice, t1_slice, t1ce_slice, t2_slice], axis=-1) \n",
    "print(\"Shape of X:\", X.shape)\n",
    "X_reshaped = X.reshape((-1, 4)).astype(np.float32) #240x240 e poi si tiene la dimensione 4, KMeans lavora su un array 2D\n",
    "print(\"Shape of X_reshaped:\", X_reshaped.shape)\n",
    "\n",
    "# === Applica K-Means ===\n",
    "km = KMeans(n_clus=k)\n",
    "km.fit(X_reshaped)\n",
    "clusters = km.getClusters()\n",
    " \n",
    "# Ritorniamo alla dimensione 240x240\n",
    "segmented_image = clusters.reshape(flair_slice.shape) \n",
    " \n",
    "# Colori clusters\n",
    "cmap_kmeans = ListedColormap(['black', 'blue', 'green', 'yellow', 'lightblue'])\n",
    " \n",
    "# Colori maschera\n",
    "labels = [0, 1, 2, 4]\n",
    "colors = ['black', 'green', 'yellow', 'lightblue']\n",
    "class_names = ['Background (0)', 'NCR & NET (1)', 'Edema (2)', 'Enhancing Tumor (4)']\n",
    "cmap_mask = ListedColormap(colors)\n",
    "norm = BoundaryNorm([0, 0.5, 1.5, 3, 5], cmap_mask.N)\n",
    " \n",
    "# === Visualizzazione ===\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12, 6))\n",
    " \n",
    "axs[0].imshow(segmented_image, cmap=cmap_kmeans)\n",
    "axs[0].set_title(f'K-Means (k={k}) - Slice {slice_idx}')\n",
    "axs[0].axis('off')\n",
    " \n",
    "axs[1].imshow(mask_slice, cmap=cmap_mask, norm=norm)\n",
    "axs[1].set_title('Ground Truth (BraTS Segmentation)')\n",
    "axs[1].axis('off')\n",
    " \n",
    "# Legenda della maschera reale\n",
    "patches = [mpatches.Patch(color=colors[i], label=class_names[i]) for i in range(len(labels))]\n",
    "axs[1].legend(handles=patches, loc='lower left', bbox_to_anchor=(1.05, 0))\n",
    " \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_clusters_to_classes(cluster_labels, true_labels):\n",
    "    \"\"\"\n",
    "    Maps K-Means cluster labels to ground truth classes using class prevalence\n",
    "    \n",
    "    Args:\n",
    "        cluster_labels (np.ndarray): Predicted cluster indices (H, W)\n",
    "        true_labels (np.ndarray): Ground truth segmentation (H, W)\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (mapped_labels, true_seg_processed) \n",
    "    \"\"\"\n",
    "    # Preprocess ground truth: map 4→3 (enhancing tumor)\n",
    "    true_seg_processed = true_labels.copy()\n",
    "    true_seg_processed[true_seg_processed == 4] = 3\n",
    "    \n",
    "    mapped_labels = np.zeros_like(cluster_labels)\n",
    "    unique_clusters = np.unique(cluster_labels)\n",
    "    \n",
    "    # Calculate class distribution in ground truth\n",
    "    class_distribution = Counter(true_seg_processed.flatten())\n",
    "    \n",
    "    for cluster in unique_clusters:\n",
    "        mask = (cluster_labels == cluster)\n",
    "        true_pixels = true_seg_processed[mask]\n",
    "        \n",
    "        # Get non-background pixels\n",
    "        non_bg_pixels = true_pixels[true_pixels != 0]\n",
    "        \n",
    "        if len(non_bg_pixels) > 0:\n",
    "            # Find most frequent non-background class\n",
    "            class_counts = Counter(non_bg_pixels)\n",
    "            mapped_class = class_counts.most_common(1)[0][0]\n",
    "        else:\n",
    "            # If only background, use most frequent class overall\n",
    "            mapped_class = class_distribution.most_common(1)[0][0]\n",
    "        \n",
    "        mapped_labels[mask] = mapped_class\n",
    "    \n",
    "    return mapped_labels, true_seg_processed\n",
    "\n",
    "def compute_kmeans_metrics(patient_id, slice_idx, k=4):\n",
    "    \"\"\"Computes segmentation metrics for K-Means on a given slice\"\"\"\n",
    "    # Load and preprocess data\n",
    "    case_path = os.path.join(TRAIN_DATASET_PATH, patient_id)\n",
    "    \n",
    "    # Load all modalities\n",
    "    flair = nib.load(os.path.join(case_path, f\"{patient_id}_flair.nii\")).get_fdata()[:, :, slice_idx]\n",
    "    t1 = nib.load(os.path.join(case_path, f\"{patient_id}_t1.nii\")).get_fdata()[:, :, slice_idx]\n",
    "    t1ce = nib.load(os.path.join(case_path, f\"{patient_id}_t1ce.nii\")).get_fdata()[:, :, slice_idx]\n",
    "    t2 = nib.load(os.path.join(case_path, f\"{patient_id}_t2.nii\")).get_fdata()[:, :, slice_idx]\n",
    "    seg = nib.load(os.path.join(case_path, f\"{patient_id}_seg.nii\")).get_fdata()[:, :, slice_idx]\n",
    "    \n",
    "    # Rescale each modality\n",
    "    flair = (flair - np.min(flair)) / (np.max(flair) - np.min(flair))\n",
    "    t1 = (t1 - np.min(t1)) / (np.max(t1) - np.min(t1))\n",
    "    t1ce = (t1ce - np.min(t1ce)) / (np.max(t1ce) - np.min(t1ce))\n",
    "    t2 = (t2 - np.min(t2)) / (np.max(t2) - np.min(t2))\n",
    "    \n",
    "    # Prepare input data\n",
    "    X = np.stack([flair, t1, t1ce, t2], axis=-1)\n",
    "    X_reshaped = X.reshape((-1, 4))\n",
    "    \n",
    "    # Apply K-Means\n",
    "    km = KMeans(n_clus=k)\n",
    "    km.fit(X_reshaped.astype(np.float32))\n",
    "    clusters = km.getClusters().reshape(flair.shape)\n",
    "    \n",
    "    # Map clusters to classes\n",
    "    mapped_seg, true_seg = map_clusters_to_classes(clusters, seg)\n",
    "    \n",
    "    # Compute metrics\n",
    "    metrics = {}\n",
    "    class_names = ['Background', 'Necrotic/Core', 'Edema', 'Enhancing']\n",
    "    \n",
    "    for class_id, class_name in enumerate(class_names):\n",
    "        true_mask = (true_seg == class_id)\n",
    "        pred_mask = (mapped_seg == class_id)\n",
    "        \n",
    "        # Dice Coefficient\n",
    "        intersection = np.logical_and(true_mask, pred_mask).sum()\n",
    "        dice = (2. * intersection) / (true_mask.sum() + pred_mask.sum() + 1e-7)\n",
    "        \n",
    "        # Sensitivity (Recall)\n",
    "        tp = np.logical_and(true_mask, pred_mask).sum()\n",
    "        fn = np.logical_and(true_mask, ~pred_mask).sum()\n",
    "        sensitivity = tp / (tp + fn + 1e-7)\n",
    "        \n",
    "        # Precision\n",
    "        fp = np.logical_and(~true_mask, pred_mask).sum()\n",
    "        precision = tp / (tp + fp + 1e-7)\n",
    "        \n",
    "        metrics[class_name] = {\n",
    "            'dice': dice,\n",
    "            'sensitivity': sensitivity,\n",
    "            'precision': precision\n",
    "        }\n",
    "    \n",
    "    # Return all necessary data including the FLAIR image for visualization\n",
    "    return metrics, clusters, mapped_seg, true_seg, flair\n",
    "\n",
    "# Example usage for patient 355, slice 95\n",
    "patient_id = \"BraTS20_Training_355\"\n",
    "slice_idx = 95\n",
    "\n",
    "# Compute metrics and get results\n",
    "metrics, clusters, mapped_seg, true_seg, flair_img = compute_kmeans_metrics(patient_id, slice_idx)\n",
    "\n",
    "# Print metrics\n",
    "print(\"K-Means Evaluation Metrics:\")\n",
    "for class_name, scores in metrics.items():\n",
    "    print(f\"{class_name}:\")\n",
    "    print(f\"  Dice = {scores['dice']:.4f}\")\n",
    "    print(f\"  Sensitivity = {scores['sensitivity']:.4f}\")\n",
    "    print(f\"  Precision = {scores['precision']:.4f}\\n\")\n",
    "\n",
    "# Visual comparison\n",
    "fig, axs = plt.subplots(1, 4, figsize=(20, 6))\n",
    "\n",
    "# Original MRI (FLAIR)\n",
    "axs[0].imshow(flair_img, cmap=\"gray\")\n",
    "axs[0].set_title('FLAIR Image')\n",
    "axs[0].axis('off')\n",
    "\n",
    "# K-Means clusters\n",
    "axs[1].imshow(clusters, cmap=\"viridis\")\n",
    "axs[1].set_title('K-Means Clusters')\n",
    "axs[1].axis('off')\n",
    "\n",
    "# Mapped segmentation\n",
    "colors = ['black', 'green', 'yellow', 'lightblue']\n",
    "class_names = ['Background', 'Necrotic/Core', 'Edema', 'Enhancing']\n",
    "cmap_mapped = ListedColormap(colors)\n",
    "axs[2].imshow(mapped_seg, cmap=cmap_mapped, \n",
    "              norm=BoundaryNorm([-0.5, 0.5, 1.5, 2.5, 3.5], 4))\n",
    "axs[2].set_title('Mapped Segmentation')\n",
    "axs[2].axis('off')\n",
    "\n",
    "# Ground Truth\n",
    "axs[3].imshow(true_seg, cmap=cmap_mapped, \n",
    "             norm=BoundaryNorm([-0.5, 0.5, 1.5, 2.5, 3.5], 4))\n",
    "axs[3].set_title('Ground Truth')\n",
    "axs[3].axis('off')\n",
    "\n",
    "# Add legend\n",
    "patches = [plt.Rectangle((0,0),1,1, color=colors[i]) for i in range(4)]\n",
    "plt.figlegend(patches, class_names, loc='lower center', ncol=4)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(bottom=0.15)  # Make space for legend\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-Negative Matrix Factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "\n",
    "def map_nmf_to_classes(component_labels, true_labels):\n",
    "    \"\"\"\n",
    "    Maps NMF component labels to ground truth classes using class prevalence\n",
    "    \"\"\"\n",
    "    # Preprocess ground truth: map 4→3 (enhancing tumor)\n",
    "    true_seg_processed = true_labels.copy()\n",
    "    true_seg_processed[true_seg_processed == 4] = 3\n",
    "    \n",
    "    mapped_labels = np.zeros_like(component_labels)\n",
    "    unique_comps = np.unique(component_labels)\n",
    "    \n",
    "    # Calculate class distribution in ground truth\n",
    "    class_distribution = Counter(true_seg_processed.flatten())\n",
    "    \n",
    "    for comp in unique_comps:\n",
    "        mask = (component_labels == comp)\n",
    "        true_pixels = true_seg_processed[mask]\n",
    "        \n",
    "        # Get non-background pixels\n",
    "        non_bg_pixels = true_pixels[true_pixels != 0]\n",
    "        \n",
    "        if len(non_bg_pixels) > 0:\n",
    "            # Find most frequent non-background class\n",
    "            class_counts = Counter(non_bg_pixels)\n",
    "            mapped_class = class_counts.most_common(1)[0][0]\n",
    "        else:\n",
    "            # If only background, use most frequent class overall\n",
    "            mapped_class = class_distribution.most_common(1)[0][0]\n",
    "        \n",
    "        mapped_labels[mask] = mapped_class\n",
    "    \n",
    "    return mapped_labels, true_seg_processed\n",
    "\n",
    "def compute_nmf_metrics(patient_id, slice_idx, n_components=4):\n",
    "    \"\"\"Computes segmentation metrics for NMF on a given slice\"\"\"\n",
    "    # Load and preprocess data\n",
    "    case_path = os.path.join(TRAIN_DATASET_PATH, patient_id)\n",
    "    \n",
    "    # Load all modalities\n",
    "    flair = nib.load(os.path.join(case_path, f\"{patient_id}_flair.nii\")).get_fdata()[:, :, slice_idx]\n",
    "    t1 = nib.load(os.path.join(case_path, f\"{patient_id}_t1.nii\")).get_fdata()[:, :, slice_idx]\n",
    "    t1ce = nib.load(os.path.join(case_path, f\"{patient_id}_t1ce.nii\")).get_fdata()[:, :, slice_idx]\n",
    "    t2 = nib.load(os.path.join(case_path, f\"{patient_id}_t2.nii\")).get_fdata()[:, :, slice_idx]\n",
    "    seg = nib.load(os.path.join(case_path, f\"{patient_id}_seg.nii\")).get_fdata()[:, :, slice_idx]\n",
    "    \n",
    "    # Rescale each modality\n",
    "    flair = (flair - np.min(flair)) / (np.max(flair) - np.min(flair) + 1e-7)\n",
    "    t1 = (t1 - np.min(t1)) / (np.max(t1) - np.min(t1) + 1e-7)\n",
    "    t1ce = (t1ce - np.min(t1ce)) / (np.max(t1ce) - np.min(t1ce) + 1e-7)\n",
    "    t2 = (t2 - np.min(t2)) / (np.max(t2) - np.min(t2) + 1e-7)\n",
    "    \n",
    "    # Prepare input data\n",
    "    X = np.stack([flair, t1, t1ce, t2], axis=-1)\n",
    "    X_reshaped = X.reshape((-1, 4))\n",
    "    \n",
    "    # Apply NMF\n",
    "    nmf_model = NMF(n_components=n_components, init='nndsvda', max_iter=200, random_state=42)\n",
    "    W = nmf_model.fit_transform(np.maximum(X_reshaped, 0))\n",
    "    components = np.argmax(W, axis=1).reshape(flair.shape)\n",
    "    \n",
    "    # Map components to classes\n",
    "    mapped_seg, true_seg = map_nmf_to_classes(components, seg)\n",
    "    \n",
    "    # Compute metrics\n",
    "    metrics = {}\n",
    "    class_names = ['Background', 'Necrotic/Core', 'Edema', 'Enhancing']\n",
    "    \n",
    "    for class_id, class_name in enumerate(class_names):\n",
    "        true_mask = (true_seg == class_id)\n",
    "        pred_mask = (mapped_seg == class_id)\n",
    "        \n",
    "        # Dice Coefficient\n",
    "        intersection = np.logical_and(true_mask, pred_mask).sum()\n",
    "        dice = (2. * intersection) / (true_mask.sum() + pred_mask.sum() + 1e-7)\n",
    "        \n",
    "        # Sensitivity (Recall)\n",
    "        tp = np.logical_and(true_mask, pred_mask).sum()\n",
    "        fn = np.logical_and(true_mask, ~pred_mask).sum()\n",
    "        sensitivity = tp / (tp + fn + 1e-7)\n",
    "        \n",
    "        # Precision\n",
    "        fp = np.logical_and(~true_mask, pred_mask).sum()\n",
    "        precision = tp / (tp + fp + 1e-7)\n",
    "        \n",
    "        metrics[class_name] = {\n",
    "            'dice': dice,\n",
    "            'sensitivity': sensitivity,\n",
    "            'precision': precision\n",
    "        }\n",
    "    \n",
    "    # Return all necessary data including the FLAIR image for visualization\n",
    "    return metrics, components, mapped_seg, true_seg, flair\n",
    "\n",
    "# Example usage for patient 355, slice 95\n",
    "patient_id = \"BraTS20_Training_355\"\n",
    "slice_idx = 95\n",
    "\n",
    "# Compute metrics and get results\n",
    "metrics, components, mapped_seg, true_seg, flair_img = compute_nmf_metrics(patient_id, slice_idx)\n",
    "\n",
    "# Print metrics\n",
    "print(\"NMF Evaluation Metrics:\")\n",
    "for class_name, scores in metrics.items():\n",
    "    print(f\"{class_name}:\")\n",
    "    print(f\"  Dice = {scores['dice']:.4f}\")\n",
    "    print(f\"  Sensitivity = {scores['sensitivity']:.4f}\")\n",
    "    print(f\"  Precision = {scores['precision']:.4f}\\n\")\n",
    "\n",
    "# Visual comparison\n",
    "fig, axs = plt.subplots(1, 4, figsize=(20, 6))\n",
    "\n",
    "# Original MRI (FLAIR)\n",
    "axs[0].imshow(flair_img, cmap=\"gray\")\n",
    "axs[0].set_title('FLAIR Image')\n",
    "axs[0].axis('off')\n",
    "\n",
    "# NMF components\n",
    "axs[1].imshow(components, cmap=\"viridis\")\n",
    "axs[1].set_title('NMF Components')\n",
    "axs[1].axis('off')\n",
    "\n",
    "# Mapped segmentation\n",
    "colors = ['black', 'green', 'yellow', 'lightblue']\n",
    "class_names = ['Background', 'Necrotic/Core', 'Edema', 'Enhancing']\n",
    "cmap_mapped = ListedColormap(colors)\n",
    "axs[2].imshow(mapped_seg, cmap=cmap_mapped, \n",
    "              norm=BoundaryNorm([-0.5, 0.5, 1.5, 2.5, 3.5], 4))\n",
    "axs[2].set_title('Mapped Segmentation')\n",
    "axs[2].axis('off')\n",
    "\n",
    "# Ground Truth\n",
    "axs[3].imshow(true_seg, cmap=cmap_mapped, \n",
    "              norm=BoundaryNorm([-0.5, 0.5, 1.5, 2.5, 3.5], 4))\n",
    "axs[3].set_title('Ground Truth')\n",
    "axs[3].axis('off')\n",
    "\n",
    "# Add legend\n",
    "patches = [plt.Rectangle((0,0),1,1, color=colors[i]) for i in range(4)]\n",
    "plt.figlegend(patches, class_names, loc='lower center', ncol=4)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(bottom=0.15)  # Make space for legend\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ottieni la lista degli ID (ultime parti dei path delle directory)\n",
    "train_and_test_ids = [f.name for f in os.scandir(TRAIN_DATASET_PATH) if f.is_dir()]\n",
    "\n",
    "# Split in: 80% train+test, 20% validation\n",
    "train_test_ids, val_ids = train_test_split(train_and_test_ids, test_size=0.2, random_state=42)\n",
    "\n",
    "# Split train+test in: 85% train, 15% test (≈12% del totale va a test)\n",
    "train_ids, test_ids = train_test_split(train_test_ids, test_size=0.15, random_state=42)\n",
    "\n",
    "print(f\"Train length: {len(train_ids)}\")\n",
    "print(f\"Validation length: {len(val_ids)}\")\n",
    "print(f\"Test length: {len(test_ids)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.pie(\n",
    "        [len(train_ids), len(val_ids), len(test_ids)],\n",
    "        labels=['Train', 'Validation', 'Test'],\n",
    "       )\n",
    "\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "plt.ylabel('Number of Images')\n",
    "plt.title('Data Distribution')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEGMENT_CLASSES = {\n",
    "    0 : 'NOT tumor',\n",
    "    1 : 'NECROTIC/CORE', \n",
    "    2 : 'EDEMA',\n",
    "    3 : 'ENHANCING'\n",
    "}\n",
    "\n",
    "# Select Slices and Image Size\n",
    "VOLUME_SLICES = 100\n",
    "VOLUME_START_AT = 22 \n",
    "IMG_SIZE=128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, list_IDs, dim=(IMG_SIZE,IMG_SIZE), batch_size = 1, n_channels = 2, shuffle=True):\n",
    "        'Initialization'\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.list_IDs = list_IDs\n",
    "        self.n_channels = n_channels\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        Batch_ids = [self.list_IDs[k] for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(Batch_ids)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, Batch_ids):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        # Initialization\n",
    "        X = np.zeros((self.batch_size*VOLUME_SLICES, *self.dim, self.n_channels))\n",
    "        y = np.zeros((self.batch_size*VOLUME_SLICES, 240, 240))\n",
    "        Y = np.zeros((self.batch_size*VOLUME_SLICES, *self.dim, 4))\n",
    "\n",
    "\n",
    "        # Generate data\n",
    "        for c, i in enumerate(Batch_ids):\n",
    "            case_path = os.path.join(TRAIN_DATASET_PATH, i)\n",
    "\n",
    "            data_path = os.path.join(case_path, f'{i}_flair.nii');\n",
    "            flair = nib.load(data_path).get_fdata()\n",
    "\n",
    "            data_path = os.path.join(case_path, f'{i}_t1ce.nii');\n",
    "            t1ce = nib.load(data_path).get_fdata()\n",
    "\n",
    "            data_path = os.path.join(case_path, f'{i}_seg.nii');\n",
    "            seg = nib.load(data_path).get_fdata()\n",
    "\n",
    "            for j in range(VOLUME_SLICES):\n",
    "                 X[j +VOLUME_SLICES*c,:,:,0] = cv2.resize(flair[:,:,j+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE));\n",
    "                 X[j +VOLUME_SLICES*c,:,:,1] = cv2.resize(t1ce[:,:,j+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE));\n",
    "\n",
    "                 y[j +VOLUME_SLICES*c] = seg[:,:,j+VOLUME_START_AT];\n",
    "\n",
    "        # Generate masks\n",
    "        y[y==4] = 3;\n",
    "        mask = tf.one_hot(y, 4);\n",
    "        Y = tf.image.resize(mask, (IMG_SIZE, IMG_SIZE));\n",
    "        return X/np.max(X), Y\n",
    "\n",
    "training_generator = DataGenerator(train_ids)\n",
    "valid_generator = DataGenerator(val_ids)\n",
    "test_generator = DataGenerator(test_ids)\n",
    "\n",
    "\n",
    "print(\"Numero di batch nel training set:\", len(training_generator))\n",
    "print(\"Numero di batch nel validation set:\", len(valid_generator))\n",
    "print(\"Numero di batch nel test set:\", len(test_generator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to display one slice and its segmentation\n",
    "def display_slice_and_segmentation(flair, t1ce, segmentation):\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(10, 5))\n",
    "\n",
    "    axes[0].imshow(flair, cmap='gray')\n",
    "    axes[0].set_title('Flair')\n",
    "    axes[0].axis('off')\n",
    "\n",
    "    axes[1].imshow(t1ce, cmap='gray')\n",
    "    axes[1].set_title('T1CE')\n",
    "    axes[1].axis('off')\n",
    "\n",
    "    axes[2].imshow(segmentation) # Displaying segmentation\n",
    "    axes[2].set_title('Segmentation')\n",
    "    axes[2].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Retrieve the ninth batch from the training generator\n",
    "X_batch, Y_batch = training_generator[8]\n",
    "\n",
    "# Extract Flair, T1CE, and segmentation from the batch\n",
    "flair_batch = X_batch[:, :, :, 0]\n",
    "t1ce_batch = X_batch[:, :, :, 1]\n",
    "segmentation_batch = np.argmax(Y_batch, axis=-1)  # Convert one-hot encoded to categorical\n",
    "\n",
    "# Extract the 50th slice from Flair, T1CE, and segmentation\n",
    "slice_index = 60  # Indexing starts from 0\n",
    "slice_flair = flair_batch[slice_index]\n",
    "slice_t1ce = t1ce_batch[slice_index]\n",
    "slice_segmentation = segmentation_batch[slice_index]\n",
    "\n",
    "# Display the 50th slice and its segmentation\n",
    "display_slice_and_segmentation(slice_flair, slice_t1ce, slice_segmentation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pixel_accuracy function calculates the percentage of correctly classified pixels in an image segmentation task. It compares the predicted class and the true class for each pixel and returns the overall mean accuracy.\n",
    "However, this metric can be misleading in imbalanced datasets, where the background class is overrepresented since the model may achieve high accuracy by mostly predicting the background, while failing to correctly identify smaller but important regions like tumors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The pixel_accuracy function calculates the percentage of correctly classified pixels, \n",
    "#that is how many pixels the model predicted with the correct class out of the total number of pixels.\n",
    "def pixel_accuracy(y_true, y_pred):\n",
    "    y_true_labels = K.argmax(y_true, axis=-1)\n",
    "    y_pred_labels = K.argmax(y_pred, axis=-1)\n",
    "    matches = K.cast(K.equal(y_true_labels, y_pred_labels), dtype='float32')\n",
    "    return K.mean(matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean_iou function calculates the Intersection over Union (IoU) for each of the 4 segmentation classes: no tumor, necrotic core, edema, and enhancing tumor. For each class, it computes the area of overlap between the predicted and ground truth masks divided by the area of their union, then returns the average IoU across all classes.\n",
    "\n",
    "This metric is particularly useful in medical image segmentation tasks, as it accounts for both false positives and false negatives.\n",
    "\n",
    "IoU = (Area of Overlap) / (Area of Union) = |A ∩ B| / |A ∪ B|\n",
    "\n",
    "Where:\n",
    "A is the predicted mask and B is the ground truth mask\n",
    "\n",
    "\n",
    "The IoU loss is defined as:\n",
    "\n",
    "IoU Loss = 1 − IoU\n",
    "\n",
    "This motivates the network to enlarge the IoU in order to minimize the IoU loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The mean_iou function calculates the Intersection over Union (IoU) for each of the 4 classes (no tumor, necrotic, edema, enhancing), \n",
    "#and then returns the average IoU across all classes.\n",
    "def mean_iou(y_true, y_pred, epsilon=1e-6):\n",
    "    iou_scores = []\n",
    "    for i in range(4):\n",
    "        y_true_c = tf.reshape(y_true[:, :, :, i], [-1])\n",
    "        y_pred_c = tf.reshape(y_pred[:, :, :, i], [-1])\n",
    "        intersection = K.sum(y_true_c * y_pred_c)\n",
    "        union = K.sum(y_true_c) + K.sum(y_pred_c) - intersection\n",
    "        iou = (intersection + epsilon) / (union + epsilon)\n",
    "        iou_scores.append(iou)\n",
    "    return K.mean(tf.stack(iou_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dice_coef function computes the average Dice coefficient across 4 segmentation classes. It measures the overlap between predicted and ground truth masks:\n",
    "\n",
    "Dice = (2 x Area of overlapped) / (total Area)\n",
    " \n",
    "Dice Loss = 1 − Dice Coefficient\n",
    "\n",
    "This metric is very effective in medical image segmentation, where foreground regions (e.g., tumors) are small and imbalanced. Dice Loss gives more weight to overlapping areas, producing stronger gradients and encouraging the network to segment structures precisely, rather than defaulting to background predictions as can happen with IoU loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function dice_coef calculates the average Dice coefficient across all 4 segmentation classes.\n",
    "def dice_coef(y_true, y_pred, smooth=1.0):\n",
    "    total_dice = 0\n",
    "    for i in range(4):\n",
    "        y_true_f = tf.reshape(y_true[:, :, :, i], [-1])\n",
    "        y_pred_f = tf.reshape(y_pred[:, :, :, i], [-1])\n",
    "        intersection = K.sum(y_true_f * y_pred_f)\n",
    "        dice = (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "        total_dice += dice\n",
    "    return total_dice / 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each class (necrotic, edema, enhancing) represents a distinct tissue type with different clinical relevance.\n",
    "By computing the Dice score separately, we can better understand how well the model segments each region, rather than relying only on an average result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define per class evaluation of dice coef\n",
    "def dice_coef_necrotic(y_true, y_pred, epsilon=1e-6):\n",
    "    intersection = K.sum(K.abs(y_true[:,:,:,1] * y_pred[:,:,:,1]))\n",
    "    return (2. * intersection) / (K.sum(K.square(y_true[:,:,:,1])) + K.sum(K.square(y_pred[:,:,:,1])) + epsilon)\n",
    "\n",
    "def dice_coef_edema(y_true, y_pred, epsilon=1e-6):\n",
    "    intersection = K.sum(K.abs(y_true[:,:,:,2] * y_pred[:,:,:,2]))\n",
    "    return (2. * intersection) / (K.sum(K.square(y_true[:,:,:,2])) + K.sum(K.square(y_pred[:,:,:,2])) + epsilon)\n",
    "\n",
    "def dice_coef_enhancing(y_true, y_pred, epsilon=1e-6):\n",
    "    intersection = K.sum(K.abs(y_true[:,:,:,3] * y_pred[:,:,:,3]))\n",
    "    return (2. * intersection) / (K.sum(K.square(y_true[:,:,:,3])) + K.sum(K.square(y_pred[:,:,:,3])) + epsilon) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sensitivity function (also known as recall or true positive rate) computes how well the model detects positive pixels for each tumor class (necrotic, edema, enhancing). It ignores class 0 (background) and returns the average sensitivity across the 3 tumor regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sensitivity(y_true, y_pred, epsilon=1e-6):\n",
    "    sensitivities = []\n",
    "    for i in range(1, 4):  # class 0 is ignored\n",
    "        y_true_c = tf.reshape(y_true[:, :, :, i], [-1])\n",
    "        y_pred_c = tf.reshape(y_pred[:, :, :, i], [-1])\n",
    "        tp = K.sum(K.round(K.clip(y_true_c * y_pred_c, 0, 1)))\n",
    "        fn = K.sum(K.round(K.clip(y_true_c * (1 - y_pred_c), 0, 1)))\n",
    "        recall = tp / (tp + fn + epsilon)\n",
    "        sensitivities.append(recall)\n",
    "    return K.mean(tf.stack(sensitivities))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The precision function computes the positive predictive value for each tumor class,  measuring the proportion of predicted positive pixels that are actually positive and ignoring the background class (0). It returns the average precision across the 3 tumor regions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(y_true, y_pred, epsilon=1e-6):\n",
    "    precisions = []\n",
    "    for i in range(1, 4):  # class 0 is ignored\n",
    "        y_true_c = tf.reshape(y_true[:, :, :, i], [-1])\n",
    "        y_pred_c = tf.reshape(y_pred[:, :, :, i], [-1])\n",
    "        tp = K.sum(K.round(K.clip(y_true_c * y_pred_c, 0, 1)))\n",
    "        fp = K.sum(K.round(K.clip((1 - y_true_c) * y_pred_c, 0, 1)))\n",
    "        prec = tp / (tp + fp + epsilon)\n",
    "        precisions.append(prec)\n",
    "    return K.mean(tf.stack(precisions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The specificity function calculates the true negative rate for each tumor class, measuring the proportion of negative ground truth pixels correctly predicted as negative and ignoring the background class (0). It returns the average specificity across the 3 tumor regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "def specificity(y_true, y_pred, epsilon=1e-6):\n",
    "    specificities = []\n",
    "    for i in range(1, 4):  # class 0 is ignored\n",
    "        y_true_c = tf.reshape(y_true[:, :, :, i], [-1])\n",
    "        y_pred_c = tf.reshape(y_pred[:, :, :, i], [-1])\n",
    "        \n",
    "        tn = K.sum(K.round(K.clip((1 - y_true_c) * (1 - y_pred_c), 0, 1)))\n",
    "        fp = K.sum(K.round(K.clip((1 - y_true_c) * y_pred_c, 0, 1)))\n",
    "        \n",
    "        spec = tn / (tn + fp + epsilon)\n",
    "        specificities.append(spec)\n",
    "    \n",
    "    return K.mean(tf.stack(specificities))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_unet(inputs, ker_init, dropout):\n",
    "    conv1 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(inputs)\n",
    "    conv1 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv1)\n",
    "\n",
    "    pool = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    conv = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(pool)\n",
    "    conv = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv)\n",
    "\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv)\n",
    "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(pool1)\n",
    "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv2)\n",
    "\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(pool2)\n",
    "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv3)\n",
    "\n",
    "\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    conv5 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(pool4)\n",
    "    conv5 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv5)\n",
    "    drop5 = Dropout(dropout)(conv5)\n",
    "\n",
    "    up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(UpSampling2D(size = (2,2))(drop5))\n",
    "    merge7 = concatenate([conv3,up7], axis = 3)\n",
    "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(merge7)\n",
    "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv7)\n",
    "\n",
    "    up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(UpSampling2D(size = (2,2))(conv7))\n",
    "    merge8 = concatenate([conv2,up8], axis = 3)\n",
    "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(merge8)\n",
    "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv8)\n",
    "\n",
    "    up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(UpSampling2D(size = (2,2))(conv8))\n",
    "    merge9 = concatenate([conv,up9], axis = 3)\n",
    "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(merge9)\n",
    "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv9)\n",
    "\n",
    "    up = Conv2D(32, 2, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(UpSampling2D(size = (2,2))(conv9))\n",
    "    merge = concatenate([conv1,up], axis = 3)\n",
    "    conv = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(merge)\n",
    "    conv = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv)\n",
    "\n",
    "    conv10 = Conv2D(4, (1,1), activation = 'softmax')(conv)\n",
    "\n",
    "    return Model(inputs = inputs, outputs = conv10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = Input((IMG_SIZE, IMG_SIZE, 2))\n",
    "\n",
    "model = build_unet(input_layer, 'he_normal', 0.2)\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "              metrics = ['accuracy',tf.keras.metrics.MeanIoU(num_classes=4), dice_coef, precision, sensitivity, specificity, dice_coef_necrotic, dice_coef_edema ,dice_coef_enhancing])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "      keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "                            patience=2, min_lr=0.000001, verbose=1),\n",
    "      keras.callbacks.ModelCheckpoint(filepath = 'model_{epoch:02d}-{val_loss:.6f}.weights.h5', \n",
    "                          verbose=1, save_best_only=True, save_weights_only = True),\n",
    "      CSVLogger('training.log', separator=',', append=False)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code for training the model:\n",
    "\n",
    "\n",
    "K.clear_session()\n",
    "\n",
    "history =  model.fit(training_generator,\n",
    "                    epochs=35,\n",
    "                    steps_per_epoch=len(train_ids),\n",
    "                    callbacks= callbacks,\n",
    "                    validation_data = valid_generator\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = pd.read_csv('/Users/chiaracangelosi/Documents/1-Uni/DataScience/Dataset/data/Progetto Data/training.log', sep=',', engine='python')\n",
    "#history = pd.read_csv('C:/Users/g2not/Desktop/Università/Data Mining and Machine Learning/Progetto/training.log', sep=',', engine='python')\n",
    "\n",
    "hist = history\n",
    "\n",
    "acc = hist['accuracy']\n",
    "val_acc = hist['val_accuracy']\n",
    "\n",
    "epoch = range(len(acc))\n",
    "\n",
    "loss = hist['loss']\n",
    "val_loss = hist['val_loss']\n",
    "\n",
    "train_dice = hist['dice_coef']\n",
    "val_dice = hist['val_dice_coef']\n",
    "\n",
    "f, ax = plt.subplots(1, 4, figsize=(16, 8))\n",
    "\n",
    "ax[0].plot(epoch, acc, 'b', label='Training Accuracy')\n",
    "ax[0].plot(epoch, val_acc, 'r', label='Validation Accuracy')\n",
    "ax[0].legend()\n",
    "ax[0].set_title('Accuracy')\n",
    "\n",
    "ax[1].plot(epoch, loss, 'b', label='Training Loss')\n",
    "ax[1].plot(epoch, val_loss, 'r', label='Validation Loss')\n",
    "ax[1].legend()\n",
    "ax[1].set_title('Loss')\n",
    "\n",
    "ax[2].plot(epoch, train_dice, 'b', label='Training Dice Coef')\n",
    "ax[2].plot(epoch, val_dice, 'r', label='Validation Dice Coef')\n",
    "ax[2].legend()\n",
    "ax[2].set_title('Dice Coefficient')\n",
    "\n",
    "ax[3].plot(epoch, hist['mean_io_u'], 'b', label='Training Mean IOU')\n",
    "ax[3].plot(epoch, hist['val_mean_io_u'], 'r', label='Validation Mean IOU')\n",
    "ax[3].legend()\n",
    "ax[3].set_title('Mean IOU')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict Tumor Segmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trova l'indice dell'epoca migliore in base a val_loss\n",
    "best_epoch_idx = history['val_loss'].idxmin()\n",
    "\n",
    "# Estrai i dati dell'epoca migliore\n",
    "best_epoch = history.iloc[best_epoch_idx]\n",
    "print(f\"Migliore epoca: {int(best_epoch['epoch'])} con val_loss: {best_epoch['val_loss']:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parametri\n",
    "IMG_SIZE = 128\n",
    "\n",
    "# Trova l'epoca migliore in automatico\n",
    "best_epoch_idx = history['val_loss'].idxmin()\n",
    "best_epoch = history.iloc[best_epoch_idx]\n",
    "epoch_num = int(best_epoch['epoch'])\n",
    "val_loss = best_epoch['val_loss']\n",
    "print(f\"Loading best model weights from epoch {epoch_num} with val_loss {val_loss:.6f}\")\n",
    "\n",
    "# Costruisci e compila il modello\n",
    "input_layer = Input((IMG_SIZE, IMG_SIZE, 2))\n",
    "model = build_unet(input_layer, 'he_normal', 0.2)\n",
    "\n",
    "model.compile(\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    metrics=[\n",
    "        'accuracy',\n",
    "        tf.keras.metrics.MeanIoU(num_classes=4),\n",
    "        dice_coef, precision, sensitivity, specificity,\n",
    "        dice_coef_necrotic, dice_coef_edema, dice_coef_enhancing\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Carica i pesi migliori\n",
    "model.load_weights('/Users/chiaracangelosi/Documents/1-Uni/DataScience/Dataset/data/Progetto Data/model_34-0.030816.weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imageLoader(path):\n",
    "    image = nib.load(path).get_fdata()\n",
    "    X = np.zeros((self.batch_size*VOLUME_SLICES, *self.dim, self.n_channels))\n",
    "    for j in range(VOLUME_SLICES):\n",
    "        X[j +VOLUME_SLICES*c,:,:,0] = cv2.resize(image[:,:,j+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE));\n",
    "        X[j +VOLUME_SLICES*c,:,:,1] = cv2.resize(ce[:,:,j+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE));\n",
    "\n",
    "        y[j +VOLUME_SLICES*c] = seg[:,:,j+VOLUME_START_AT];\n",
    "    return np.array(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadDataFromDir(path, list_of_files, mriType, n_images):\n",
    "    scans = []\n",
    "    masks = []\n",
    "    for i in list_of_files[:n_images]:\n",
    "        fullPath = glob.glob( i + '/*'+ mriType +'*')[0]\n",
    "        currentScanVolume = imageLoader(fullPath)\n",
    "        currentMaskVolume = imageLoader( glob.glob( i + '/*seg*')[0] )\n",
    "        # for each slice in 3D volume, find also it's mask\n",
    "        for j in range(0, currentScanVolume.shape[2]):\n",
    "            scan_img = cv2.resize(currentScanVolume[:,:,j], dsize=(IMG_SIZE,IMG_SIZE), interpolation=cv2.INTER_AREA).astype('uint8')\n",
    "            mask_img = cv2.resize(currentMaskVolume[:,:,j], dsize=(IMG_SIZE,IMG_SIZE), interpolation=cv2.INTER_AREA).astype('uint8')\n",
    "            scans.append(scan_img[..., np.newaxis])\n",
    "            masks.append(mask_img[..., np.newaxis])\n",
    "    return np.array(scans, dtype='float32'), np.array(masks, dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showPredictsById(case, start_slice = 60):\n",
    "    path = f\"/content/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/BraTS20_Training_{case}\"\n",
    "    gt = nib.load(os.path.join(path, f'BraTS20_Training_{case}_seg.nii')).get_fdata()\n",
    "    origImage = nib.load(os.path.join(path, f'BraTS20_Training_{case}_flair.nii')).get_fdata()\n",
    "    p = predictByPath(path,case)\n",
    "\n",
    "    core = p[:,:,:,1]\n",
    "    edema= p[:,:,:,2]\n",
    "    enhancing = p[:,:,:,3]\n",
    "\n",
    "    plt.figure(figsize=(18, 50))\n",
    "    f, axarr = plt.subplots(1,6, figsize = (18, 50))\n",
    "\n",
    "    for i in range(6): # for each image, add brain background\n",
    "        axarr[i].imshow(cv2.resize(origImage[:,:,start_slice+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE)), cmap=\"gray\", interpolation='none')\n",
    "\n",
    "    axarr[0].imshow(cv2.resize(origImage[:,:,start_slice+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE)), cmap=\"gray\")\n",
    "    axarr[0].title.set_text('Original image flair')\n",
    "    curr_gt=cv2.resize(gt[:,:,start_slice+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE), interpolation = cv2.INTER_NEAREST)\n",
    "    axarr[1].imshow(curr_gt, cmap=\"Reds\", interpolation='none', alpha=0.3) # ,alpha=0.3,cmap='Reds'\n",
    "    axarr[1].title.set_text('Ground truth')\n",
    "    axarr[2].imshow(p[start_slice,:,:,1:4], cmap=\"Reds\", interpolation='none', alpha=0.3)\n",
    "    axarr[2].title.set_text('all classes predicted')\n",
    "    axarr[3].imshow(edema[start_slice,:,:], cmap=\"OrRd\", interpolation='none', alpha=0.3)\n",
    "    axarr[3].title.set_text(f'{SEGMENT_CLASSES[1]} predicted')\n",
    "    axarr[4].imshow(core[start_slice,:,], cmap=\"OrRd\", interpolation='none', alpha=0.3)\n",
    "    axarr[4].title.set_text(f'{SEGMENT_CLASSES[2]} predicted')\n",
    "    axarr[5].imshow(enhancing[start_slice,:,], cmap=\"OrRd\", interpolation='none', alpha=0.3)\n",
    "    axarr[5].title.set_text(f'{SEGMENT_CLASSES[3]} predicted')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictByPath(case_path, case):\n",
    "    # Costruisci il modello\n",
    "    input_layer = Input((IMG_SIZE, IMG_SIZE, 2))\n",
    "    model = build_unet(input_layer, 'he_normal', 0.2)\n",
    "\n",
    "    model.compile(\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "        metrics=[\n",
    "            'accuracy',\n",
    "            tf.keras.metrics.MeanIoU(num_classes=4),\n",
    "            dice_coef, precision, sensitivity, specificity,\n",
    "            dice_coef_necrotic, dice_coef_edema, dice_coef_enhancing\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Carica i pesi migliori dal file\n",
    "    model.load_weights('/Users/chiaracangelosi/Documents/1-Uni/DataScience/Dataset/data/Progetto Data/model_34-0.030816.weights.h5')\n",
    "\n",
    "    # Prepara i dati di input\n",
    "    X = np.empty((VOLUME_SLICES, IMG_SIZE, IMG_SIZE, 2))\n",
    "\n",
    "    flair = nib.load(os.path.join(case_path, f'BraTS20_Training_{case}_flair.nii')).get_fdata()\n",
    "    ce    = nib.load(os.path.join(case_path, f'BraTS20_Training_{case}_t1ce.nii')).get_fdata()\n",
    "\n",
    "    for j in range(VOLUME_SLICES):\n",
    "        X[j, :, :, 0] = cv2.resize(flair[:, :, j + VOLUME_START_AT], (IMG_SIZE, IMG_SIZE))\n",
    "        X[j, :, :, 1] = cv2.resize(ce[:, :, j + VOLUME_START_AT], (IMG_SIZE, IMG_SIZE))\n",
    "\n",
    "    # Normalizza e predici\n",
    "    return model.predict(X / np.max(X), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funzione di base per il plotting SENZA SLIDER\n",
    "def plot_prediction_slices(p, gt, origImage, slice_idx):\n",
    "    core = p[:, :, :, 1]\n",
    "    edema = p[:, :, :, 2]\n",
    "    enhancing = p[:, :, :, 3]\n",
    "\n",
    "    fig, axarr = plt.subplots(1, 6, figsize=(24, 6))\n",
    "\n",
    "    background = cv2.resize(origImage[:, :, slice_idx + VOLUME_START_AT], (IMG_SIZE, IMG_SIZE))\n",
    "\n",
    "    axarr[0].imshow(background, cmap=\"gray\")\n",
    "    axarr[0].set_title('Original FLAIR')\n",
    "\n",
    "    gt_slice = cv2.resize(gt[:, :, slice_idx + VOLUME_START_AT], (IMG_SIZE, IMG_SIZE), interpolation=cv2.INTER_NEAREST)\n",
    "    axarr[1].imshow(background, cmap=\"gray\")\n",
    "    axarr[1].imshow(gt_slice, cmap=\"turbo\", interpolation='none', alpha=0.3)\n",
    "    axarr[1].set_title('Ground Truth')\n",
    "\n",
    "    prediction_all = p[slice_idx, :, :, 1:4]\n",
    "    axarr[2].imshow(background, cmap=\"gray\")\n",
    "    axarr[2].imshow(np.sum(prediction_all, axis=-1), cmap=\"turbo\", interpolation='none', alpha=0.3)\n",
    "    axarr[2].set_title('All Classes Predicted')\n",
    "\n",
    "    axarr[3].imshow(background, cmap=\"gray\")\n",
    "    axarr[3].imshow(edema[slice_idx, :, :], cmap=\"turbo\", interpolation='none', alpha=0.3)\n",
    "    axarr[3].set_title(f'{SEGMENT_CLASSES[2]} Predicted')\n",
    "\n",
    "    axarr[4].imshow(background, cmap=\"gray\")\n",
    "    axarr[4].imshow(core[slice_idx, :, :], cmap=\"turbo\", interpolation='none', alpha=0.3)\n",
    "    axarr[4].set_title(f'{SEGMENT_CLASSES[1]} Predicted')\n",
    "\n",
    "    axarr[5].imshow(background, cmap=\"gray\")\n",
    "    axarr[5].imshow(enhancing[slice_idx, :, :], cmap=\"turbo\", interpolation='none', alpha=0.3)\n",
    "    axarr[5].set_title(f'{SEGMENT_CLASSES[3]} Predicted')\n",
    "\n",
    "    for ax in axarr:\n",
    "        ax.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Funzione per un caso (visualizzazione statica)\n",
    "def showPredictsById(case_number, slice_idx=60):\n",
    "    case_id = f\"BraTS20_Training_{case_number}\"\n",
    "    path = os.path.join(TRAIN_DATASET_PATH, case_id)\n",
    "\n",
    "    gt_path = os.path.join(path, f\"{case_id}_seg.nii\")\n",
    "    flair_path = os.path.join(path, f\"{case_id}_flair.nii\")\n",
    "\n",
    "    gt = nib.load(gt_path).get_fdata()\n",
    "    origImage = nib.load(flair_path).get_fdata()\n",
    "    p = predictByPath(path, case_number)\n",
    "\n",
    "    plot_prediction_slices(p, gt, origImage, slice_idx)\n",
    "\n",
    "# Funzione per un caso (interattivo con slider)\n",
    "def interactiveShowPredictsById(case_number):\n",
    "    case_id = f\"BraTS20_Training_{case_number}\"\n",
    "    path = os.path.join(TRAIN_DATASET_PATH, case_id)\n",
    "\n",
    "    gt_path = os.path.join(path, f\"{case_id}_seg.nii\")\n",
    "    flair_path = os.path.join(path, f\"{case_id}_flair.nii\")\n",
    "\n",
    "    gt = nib.load(gt_path).get_fdata()\n",
    "    origImage = nib.load(flair_path).get_fdata()\n",
    "    p = predictByPath(path, case_number)\n",
    "\n",
    "    def plot_wrapper(slice_idx):\n",
    "        plot_prediction_slices(p, gt, origImage, slice_idx)\n",
    "\n",
    "    slider = widgets.IntSlider(value=60, min=0, max=VOLUME_SLICES-1, step=1, description='Slice:')\n",
    "    widgets.interact(plot_wrapper, slice_idx=slider)\n",
    "\n",
    "# Funzione per visualizzare più casi in sequenza\n",
    "def showMultiplePredictsByIds(case_numbers, slice_idx=60):\n",
    "    for case_number in case_numbers:\n",
    "        print(f\"=== Case {case_number} ===\")\n",
    "        showPredictsById(case_number, slice_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estrai ultimi 3 caratteri da ogni ID\n",
    "case_numbers = [id[-3:] for id in test_ids[:3]]\n",
    "\n",
    "# Visualizza in sequenza il slice 60 per ciascuno\n",
    "showMultiplePredictsByIds(case_numbers, slice_idx=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualizzazione con slider\n",
    "\n",
    "def interactiveShowMultipleCasesSynced(case_numbers):\n",
    "    all_data = []\n",
    "    for case_number in case_numbers:\n",
    "        case_id = f\"BraTS20_Training_{case_number}\"\n",
    "        path = os.path.join(TRAIN_DATASET_PATH, case_id)\n",
    "\n",
    "        gt_path = os.path.join(path, f\"{case_id}_seg.nii\")\n",
    "        flair_path = os.path.join(path, f\"{case_id}_flair.nii\")\n",
    "\n",
    "        gt = nib.load(gt_path).get_fdata()\n",
    "        origImage = nib.load(flair_path).get_fdata()\n",
    "        p = predictByPath(path, case_number)\n",
    "\n",
    "        all_data.append((case_number, p, gt, origImage))\n",
    "\n",
    "    def plot_all_cases(slice_idx):\n",
    "        n = len(all_data)\n",
    "        fig, axs = plt.subplots(n, 6, figsize=(24, 6 * n))\n",
    "        axs = np.atleast_2d(axs)  # forza axs ad avere sempre forma (n, 6)\n",
    " \n",
    "\n",
    "\n",
    "        for i, (case_number, p, gt, origImage) in enumerate(all_data):\n",
    "            \n",
    "                 \n",
    "            core = p[:, :, :, 1]\n",
    "            edema = p[:, :, :, 2]\n",
    "            enhancing = p[:, :, :, 3]\n",
    "\n",
    "            # Estrai la slice una volta sola e ridimensiona\n",
    "            flair_slice = origImage[:, :, slice_idx + VOLUME_START_AT]\n",
    "            flair_resized = cv2.resize(flair_slice, (IMG_SIZE, IMG_SIZE))\n",
    "\n",
    "            gt_slice = gt[:, :, slice_idx + VOLUME_START_AT]\n",
    "            gt_resized = cv2.resize(gt_slice, (IMG_SIZE, IMG_SIZE), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "            pred_all = np.sum(p[slice_idx, :, :, 1:4], axis=-1)\n",
    "            pred_all_resized = cv2.resize(pred_all, (IMG_SIZE, IMG_SIZE), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "            edema_resized = cv2.resize(edema[slice_idx, :, :], (IMG_SIZE, IMG_SIZE), interpolation=cv2.INTER_NEAREST)\n",
    "            core_resized = cv2.resize(core[slice_idx, :, :], (IMG_SIZE, IMG_SIZE), interpolation=cv2.INTER_NEAREST)\n",
    "            enh_resized = cv2.resize(enhancing[slice_idx, :, :], (IMG_SIZE, IMG_SIZE), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "            axs[i, 0].imshow(flair_resized, cmap=\"gray\")\n",
    "            axs[i, 0].set_title(f'{case_number} - FLAIR')\n",
    "\n",
    "            axs[i, 1].imshow(flair_resized, cmap=\"gray\")\n",
    "            axs[i, 1].imshow(gt_resized, cmap=\"turbo\", alpha=0.3, interpolation='none')\n",
    "            axs[i, 1].set_title('Ground Truth')\n",
    "\n",
    "            axs[i, 2].imshow(flair_resized, cmap=\"gray\")\n",
    "            axs[i, 2].imshow(pred_all_resized, cmap=\"turbo\", alpha=0.3, interpolation='none')\n",
    "            axs[i, 2].set_title('All Predicted')\n",
    "\n",
    "            axs[i, 3].imshow(flair_resized, cmap=\"gray\")\n",
    "            axs[i, 3].imshow(edema_resized, cmap=\"turbo\", alpha=0.3, interpolation='none')\n",
    "            axs[i, 3].set_title(f'{SEGMENT_CLASSES[2]}')\n",
    "\n",
    "            axs[i, 4].imshow(flair_resized, cmap=\"gray\")\n",
    "            axs[i, 4].imshow(core_resized, cmap=\"turbo\", alpha=0.3, interpolation='none')\n",
    "            axs[i, 4].set_title(f'{SEGMENT_CLASSES[1]}')\n",
    "\n",
    "            axs[i, 5].imshow(flair_resized, cmap=\"gray\")\n",
    "            axs[i, 5].imshow(enh_resized, cmap=\"turbo\", alpha=0.3, interpolation='none')\n",
    "            axs[i, 5].set_title(f'{SEGMENT_CLASSES[3]}')\n",
    "        \n",
    "            for ax in axs[i]:\n",
    "                ax.axis('off')\n",
    "            \n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        plt.close(fig)\n",
    "\n",
    "    slider = widgets.IntSlider(value=60, min=0, max=VOLUME_SLICES - 1, step=1, description='Slice:')\n",
    "    out = widgets.interactive_output(plot_all_cases, {'slice_idx': slider})\n",
    "    display(widgets.VBox([slider, out]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case_numbers = [id[-3:] for id in test_ids[:3]]\n",
    "interactiveShowMultipleCasesSynced(case_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interactiveComparePredGtHorizontal(case_number):\n",
    "\n",
    "    case_id = f\"BraTS20_Training_{case_number}\"\n",
    "    path = os.path.join(TRAIN_DATASET_PATH, case_id)\n",
    "\n",
    "    gt_path = os.path.join(path, f\"{case_id}_seg.nii\")\n",
    "    flair_path = os.path.join(path, f\"{case_id}_flair.nii\")\n",
    "\n",
    "    gt = nib.load(gt_path).get_fdata()\n",
    "    origImage = nib.load(flair_path).get_fdata()\n",
    "    p = predictByPath(path, case_number)\n",
    "\n",
    "    classes = {\n",
    "        'Core': 1,\n",
    "        'Edema': 2,\n",
    "        'Enhancing': 3\n",
    "    }\n",
    "\n",
    "\n",
    "    def plot_slice(slice_idx, show_gt, show_pred, show_errors, show_core, show_edema, show_enhancing):\n",
    "\n",
    "        background = cv2.resize(origImage[:, :, slice_idx + VOLUME_START_AT], (IMG_SIZE, IMG_SIZE))\n",
    "        gt_slice = cv2.resize(gt[:, :, slice_idx + VOLUME_START_AT], (IMG_SIZE, IMG_SIZE), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "        pred_probs = p[slice_idx, :, :, 1:4]\n",
    "        pred_bin = (pred_probs > 0.5).astype(np.uint8)\n",
    "\n",
    "        selected_classes = []\n",
    "        if show_core:\n",
    "            selected_classes.append('Core')\n",
    "        if show_edema:\n",
    "            selected_classes.append('Edema')\n",
    "        if show_enhancing:\n",
    "            selected_classes.append('Enhancing')\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(4, 4))\n",
    "    \n",
    "        ax.imshow(background, cmap='gray')\n",
    "\n",
    "        combined_overlay = np.zeros(background.shape + (4,))  # RGBA overlay\n",
    "\n",
    "        if show_gt:\n",
    "            for cls_name in selected_classes:\n",
    "                mask = (gt_slice == classes[cls_name])\n",
    "                color = np.zeros(4)\n",
    "                if cls_name == 'Core': color = [1, 0, 0, 0.3]\n",
    "                elif cls_name == 'Edema': color = [0, 1, 0, 0.3]\n",
    "                elif cls_name == 'Enhancing': color = [0, 0, 1, 0.3]\n",
    "                overlay = np.zeros_like(combined_overlay)\n",
    "                overlay[mask] = color\n",
    "                combined_overlay = np.maximum(combined_overlay, overlay)\n",
    "\n",
    "        if show_pred:\n",
    "            for cls_name in selected_classes:\n",
    "                cls_idx = classes[cls_name] - 1\n",
    "                mask = (pred_bin[:, :, cls_idx] == 1)\n",
    "                color = np.zeros(4)\n",
    "                if cls_name == 'Core': color = [1, 0, 0, 0.5]\n",
    "                elif cls_name == 'Edema': color = [0, 1, 0, 0.5]\n",
    "                elif cls_name == 'Enhancing': color = [0, 0, 1, 0.5]\n",
    "                overlay = np.zeros_like(combined_overlay)\n",
    "                overlay[mask] = color\n",
    "                combined_overlay = np.maximum(combined_overlay, overlay)\n",
    "\n",
    "        if show_errors:\n",
    "            gt_bin = (gt_slice > 0).astype(np.uint8)\n",
    "            pred_bin_all = (np.sum(pred_bin, axis=2) > 0).astype(np.uint8)\n",
    "\n",
    "            false_positive = np.logical_and(pred_bin_all == 1, gt_bin == 0)\n",
    "            false_negative = np.logical_and(pred_bin_all == 0, gt_bin == 1)\n",
    "            true_positive = np.logical_and(pred_bin_all == 1, gt_bin == 1)\n",
    "\n",
    "            overlay_fp = np.zeros_like(combined_overlay)\n",
    "            overlay_fp[false_positive] = [1, 0, 0, 0.2]\n",
    "            combined_overlay = np.maximum(combined_overlay, overlay_fp)\n",
    "\n",
    "            overlay_fn = np.zeros_like(combined_overlay)\n",
    "            overlay_fn[false_negative] = [0, 0, 1, 0.2]\n",
    "            combined_overlay = np.maximum(combined_overlay, overlay_fn)\n",
    "\n",
    "            overlay_tp = np.zeros_like(combined_overlay)\n",
    "            overlay_tp[true_positive] = [0, 1, 0, 0.2]\n",
    "            combined_overlay = np.maximum(combined_overlay, overlay_tp)\n",
    "\n",
    "        ax.imshow(combined_overlay)\n",
    "\n",
    "        ax.axis('off')\n",
    "        ax.set_title(f\"Slice {slice_idx} - GT and Prediction overlay\")\n",
    "        #plt.show()\n",
    "\n",
    "    # Slider in una riga da solo\n",
    "    slice_slider = widgets.IntSlider(value=60, min=0, max=VOLUME_SLICES-1, step=1, description='Slice', layout=widgets.Layout(width='80%'))\n",
    "\n",
    "    # Checkboxes in una seconda riga compatta\n",
    "    checkboxes = widgets.HBox([\n",
    "        widgets.Checkbox(value=True, description='Show Ground Truth'),\n",
    "        widgets.Checkbox(value=True, description='Show Prediction'),\n",
    "        widgets.Checkbox(value=True, description='Show Error Map'),\n",
    "        widgets.Checkbox(value=True, description='Core'),\n",
    "        widgets.Checkbox(value=True, description='Edema'),\n",
    "        widgets.Checkbox(value=True, description='Enhancing')\n",
    "    ])\n",
    "\n",
    "    # Recupero singoli checkbox per la funzione di callback\n",
    "    show_gt = checkboxes.children[0]\n",
    "    show_pred = checkboxes.children[1]\n",
    "    show_errors = checkboxes.children[2]\n",
    "    show_core = checkboxes.children[3]\n",
    "    show_edema = checkboxes.children[4]\n",
    "    show_enhancing = checkboxes.children[5]\n",
    "\n",
    "    # Output della figura\n",
    "    out = widgets.interactive_output(\n",
    "        plot_slice,\n",
    "        {\n",
    "            'slice_idx': slice_slider,\n",
    "            'show_gt': show_gt,\n",
    "            'show_pred': show_pred,\n",
    "            'show_errors': show_errors,\n",
    "            'show_core': show_core,\n",
    "            'show_edema': show_edema,\n",
    "            'show_enhancing': show_enhancing\n",
    "        }\n",
    "    )\n",
    "\n",
    "    display(slice_slider, checkboxes, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactiveComparePredGtHorizontal('196')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    metrics=[\n",
    "        'accuracy',\n",
    "        tf.keras.metrics.MeanIoU(num_classes=4),\n",
    "        dice_coef,\n",
    "        precision,\n",
    "        sensitivity,\n",
    "        specificity,\n",
    "        dice_coef_necrotic,\n",
    "        dice_coef_edema,\n",
    "        dice_coef_enhancing\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "results = model.evaluate(test_generator, batch_size=100, callbacks=callbacks)\n",
    "\n",
    "# Metric labels\n",
    "descriptions = [\n",
    "    \"Loss\",\n",
    "    \"Accuracy\",\n",
    "    \"Mean IoU\",\n",
    "    \"Dice coefficient\",\n",
    "    \"Precision\",\n",
    "    \"Sensitivity\",\n",
    "    \"Specificity\",\n",
    "    \"Dice coef Necrotic\",\n",
    "    \"Dice coef Edema\",\n",
    "    \"Dice coef Enhancing\"\n",
    "]\n",
    "\n",
    "print(\"\\n Model evaluation on the test set:\")\n",
    "print(\"====================================\")\n",
    "\n",
    "# Ensure results and labels have the same length\n",
    "if len(results) != len(descriptions):\n",
    "    print(f\"⚠️ Warning: {len(results)} results vs {len(descriptions)} descriptions!\")\n",
    "    min_len = min(len(results), len(descriptions))\n",
    "else:\n",
    "    min_len = len(results)\n",
    "\n",
    "# Print formatted results\n",
    "for desc, value in zip(descriptions[:min_len], results[:min_len]):\n",
    "    print(f\"{desc:<20}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TO DO LIST:\n",
    "Hausdorff distance in the Metrics Section\n",
    "Metrics on the K-Means result\n",
    "Predict and Evaluation sections from Kaggle\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
